<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Spring Boot-enabled business process automation with Red Hat Process Automation Manager</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/1vJj6lnr8T4/" /><category term="Drools" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="jboss bpm suite" scheme="searchisko:content:tags" /><category term="jBPM" scheme="searchisko:content:tags" /><category term="kie" scheme="searchisko:content:tags" /><category term="KIE Server" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="microservices" scheme="searchisko:content:tags" /><category term="Modern App Dev" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift" scheme="searchisko:content:tags" /><category term="Red Hat Process Automation Manager" scheme="searchisko:content:tags" /><category term="RHPAM" scheme="searchisko:content:tags" /><category term="Spring Boot" scheme="searchisko:content:tags" /><author><name>Duncan Doyle</name></author><id>searchisko:content:id:jbossorg_blog-spring_boot_enabled_business_process_automation_with_red_hat_process_automation_manager</id><updated>2018-11-01T12:00:11Z</updated><published>2018-11-01T12:00:11Z</published><content type="html">&lt;p&gt;With the release of version 7.1 of &lt;a href="https://developers.redhat.com/products/rhpam/overview/"&gt;Red Hat Process Automation Manager&lt;/a&gt; (RHPAM), the platform now supports the deployment of the process automation manager runtime as a &amp;#8220;capability&amp;#8221; within Spring Boot applications. As Maciej Swiderski, the project lead for &lt;a href="https://www.jbpm.org"&gt;jBPM.org&lt;/a&gt; (the upstream community project for RHPAM) &lt;a href="http://mswiderski.blogspot.com/2018/01/spring-boot-starters-for-jbpm-and-kie.html"&gt;explained earlier this year&lt;/a&gt;, the KIE (Knowledge Is Everything) platform on which RHPAM is built provides &lt;em&gt;Spring Boot Starters&lt;/em&gt; to quickly build a business application or &lt;a href="https://developers.redhat.com/topics/microservices/"&gt;microservice&lt;/a&gt; with process and case execution capabilities using a minimal amount of code.&lt;/p&gt; &lt;p&gt;&lt;span id="more-523727"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Spring Boot Starters comprise a set of dependency descriptors that can be added to your application to easily set up the right dependencies for your project. RHPAM now provides support for the following five starters. This gives you the flexibility to choose exactly the process automation functionality you need in your Spring Boot application:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;jbpm-spring-boot-starter-basic&lt;/code&gt;: Adds &lt;a href="http://www.jbpm.org"&gt;jBPM&lt;/a&gt; capabilities to your application. It provides the &lt;a href="http://www.jbpm.org"&gt;jBPM&lt;/a&gt;/RHPAM-embedded runtime and services to run the process execution engine within your application.&lt;/li&gt; &lt;li&gt;&lt;code&gt;kie-server-spring-boot-starter&lt;/code&gt;: Adds KIE Server capabilities to your application. This allows you to run the KIE Server services and RESTful APIs within your application. This starter provides all the business automation features that Process Automation Manager has to offer. This includes process and case execution (&lt;a href="http://www.jbpm.org"&gt;jBPM&lt;/a&gt;), (business) rules and DMN (Decision Model &amp;#38; Notation) execution (&lt;a href="http://www.drools.org"&gt;Drools&lt;/a&gt;), and business resource optimization (&lt;a href="http://www.optaplanner.org"&gt;OptaPlanner&lt;/a&gt;).&lt;/li&gt; &lt;li&gt;&lt;code&gt;kie-server-spring-boot-starter-drools&lt;/code&gt;: Same as &lt;code&gt;kie-server-spring-boot-starter&lt;/code&gt;, but has only rules and DMN execution (&lt;a href="http://www.drools.org"&gt;Drools&lt;/a&gt;) capabilities.&lt;/li&gt; &lt;li&gt;&lt;code&gt;kie-server-spring-boot-starter-jbpm&lt;/code&gt;: Same as &lt;code&gt;kie-server-spring-boot-starter&lt;/code&gt;, but has only rules and process and case execution (jBPM) capabilities.&lt;/li&gt; &lt;li&gt;&lt;code&gt;kie-server-spring-boot-starter-optaplanner&lt;/code&gt;: Same as the &lt;code&gt;kie-server-spring-boot-starter&lt;/code&gt;, but has only business resource optimization (&lt;a href="http://www.optaplanner.org"&gt;OptaPlanner&lt;/a&gt;) capabilities.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Cloud-native process automation capabilities&lt;/h2&gt; &lt;p&gt;The KIE Spring Boot Starters enable new and interesting ways to deploy business automation capabilities in IT architectures. In the cloud and container world of today, business process execution is starting to shift from the traditional, centralized deployments of process execution engines (from the SOA era) to a more agile, de-centralized deployment of smaller process definitions. These smaller process deployments fit extremely well in a &lt;a href="https://developers.redhat.com/topics/microservices/"&gt;microservices&lt;/a&gt; architecture. In these architectures, they can either orchestrate microservices, be part of a microservices choreography, or be a mix of both.&lt;/p&gt; &lt;p&gt;The diagram below shows a high-level overview of how the jBPM process execution engine can be deployed as a capability within a microservices architecture. In this example, both the &lt;em&gt;Order Service&lt;/em&gt; and &lt;em&gt;Shipping Service&lt;/em&gt; use the process execution capability of jBPM, while the &lt;em&gt;Pricing Service&lt;/em&gt; and &lt;em&gt;Promotion Service&lt;/em&gt; use the rules execution capability of Drools.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-2018-10-03-at-17.17.56.png"&gt;&lt;img class=" aligncenter wp-image-523787 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-2018-10-03-at-17.17.56-1024x455.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-2018-10-03-at-17.17.56-1024x455.png" alt="High-level overview of how the jBPM process execution engine can be deployed as a capability within a microservices architecture" width="640" height="284" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-2018-10-03-at-17.17.56-1024x455.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-2018-10-03-at-17.17.56-300x133.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-2018-10-03-at-17.17.56-768x341.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Lightweight runtimes and deployment models are needed that can run these process instances in a cloud-native way on modern container platforms such as &lt;a href="http://openshift.com/"&gt;Red Hat OpenShift&lt;/a&gt;. Version 7.0 of Process Automation Manager already provides full support for OpenShift deployments with OpenShift KIE Server images. Version 7.1 provides the developer community even more flexibility by allowing developers to integrate advanced business automation capabilities in their Spring Boot applications and microservices and deploy them on modern &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt; clusters. This enables the development of even smaller, lighter services with more-advanced capabilities to automate business process execution, business rules execution and evaluation, and business resource optimization.&lt;/p&gt; &lt;h2&gt;Enterprise process management&lt;/h2&gt; &lt;p&gt;With the introduction of more lightweight options for automating business process management and execution, enterprise-class management capabilities and insights into these automated processes still need to be provided. After all, these processes implement the value chain of the organization and, therefore, need to be effectively managed. As such, KIE Server enabled Spring Boot runtimes integrate with the KIE Server Controller and KIE Server SmartRouter, enabling easy integration with the Process Automation Manager Business Central workbench. This enables end users to monitor and manage their distributed, containerized, business automation topology from a centralized (or distributed!) admin console.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-2018-10-03-at-17.52.35.png"&gt;&lt;img class=" aligncenter wp-image-523827 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-2018-10-03-at-17.52.35-1024x291.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-2018-10-03-at-17.52.35.png" alt="KIE-Server capability deployed in a Spring Boot application" width="3360" height="954" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-2018-10-03-at-17.52.35.png 3360w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-2018-10-03-at-17.52.35-300x85.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-2018-10-03-at-17.52.35-768x218.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screenshot-2018-10-03-at-17.52.35-1024x291.png 1024w" sizes="(max-width: 3360px) 100vw, 3360px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;As can be seen in the screenshot above, KIE Server capability deployed in a Spring Boot application is registered as a &amp;#8220;managed&amp;#8221; KIE Server runtime within the Business Central management console. This allows system administrators and operators to efficiently and effectively manage the enterprise process runtime, even in a distributed, cloud-native and containerized runtime topology.&lt;/p&gt; &lt;h2&gt;Demo&lt;/h2&gt; &lt;p&gt;A demo of this new functionality is provided with the new &lt;em&gt;Order IT Hardware&lt;/em&gt; demo in the &lt;a href="https://github.com/jbossdemocentral/rhpam7-order-it-hw-demo"&gt;JBoss Demo Central GitHub repository&lt;/a&gt;. The application demonstrates an IT hardware order system, built on the case management capabilities of Process Automation Manager 7. The process engine and KIE Server run embedded in a Spring Boot application and are managed by the RHPAM Business Central workbench. Furthermore, RESTful integration with a Vert.x microservice is demonstrated, as well as an implementation of the &lt;a href="https://microservices.io/patterns/data/saga.html"&gt;Saga Pattern&lt;/a&gt; in BPMN2.&lt;/p&gt; &lt;p&gt;The code of the Spring Boot application can be found &lt;a href="https://github.com/jbossdemocentral/rhpam7-order-it-hw-demo-springboot-app"&gt;here&lt;/a&gt;. &lt;a href="https://github.com/jbossdemocentral/rhpam7-order-it-hw-demo-springboot-app/blob/master/pom.xml#L31-L35"&gt;This dependency&lt;/a&gt; in the project&amp;#8217;s Maven POM file shows the configuration of the KIE Server Spring Boot Starter. By simply marking the application as a Spring Boot application through the &lt;a href="https://github.com/DuncanDoyle/order-it-hw-app/blob/master/src/main/java/org/jbpm/cases/orderithwapp/OrderItHwAppApplication.java#L15"&gt;@SpringBootApplication&lt;/a&gt; annotation, the KIE Server capabilities are bootstrapped inside the application.&lt;/p&gt; &lt;p&gt;The demo includes a complete walkthrough guide that provides full instructions on how to set up the demo on OpenShift and run through a full end-to-end use-case.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;With the release of Red Hat Process Automation Manager 7.1, developers of modern, light-weight applications on Spring Boot now have the ability to enhance and augment their applications with business process and business rules execution capabilities through the new KIE Spring Boot Starters. With the support of these business applications and services on OpenShift, Red Hat Process Automation Manager enables the implementation of distributed process and rules management on modern container platforms. At the same time, the integration with the Business Central workbench provides enterprise-wide capabilities to effectively and efficiently monitor and manage these business processes and rules in a distributed production environment.&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;div&gt; &lt;p&gt;&lt;img class="alignleft" title="Duncan Doyle" src="https://i0.wp.com/en.gravatar.com/userimage/106146330/2f0c06257ede9b94dfb276ccbdb8cab4.jpg" alt="Duncan Doyle" width="119" height="119" /&gt;&lt;/p&gt; &lt;h3&gt;About the author:&lt;/h3&gt; &lt;p&gt;&lt;a href="http://twitter.com/DuncanDoyle" target="_blank" rel="noopener"&gt;Duncan Doyle&lt;/a&gt; is the Technical Marketing Manager for the Red Hat Business Automation platforms at Red Hat. With a background in Red Hat Consulting and Services, Duncan has worked extensively with large Red Hat customers to build advanced, open-source, business-rules and business process management solutions.&lt;/p&gt; &lt;p&gt;He has a strong background in technologies and concepts like Service Oriented Architecture, Continuous Integration &amp;#38; Delivery, rules engines and BPM platforms and is a subject matter expert (SME) on multiple JBoss Middleware technologies, including, but not limited to, JBoss EAP, HornetQ, Fuse, DataGrid, BRMS and BPMSuite. When he’s not working on open-source solutions and technology, he is building Lego with his son and daughter or jamming along some 90’s rock-music on his Fender Stratocaster.&lt;/p&gt; &lt;/div&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F11%2F01%2Fspring-boot-enabled-business-process-automation-with-red-hat-process-automation-manager%2F&amp;#38;linkname=Spring%20Boot-enabled%20business%20process%20automation%20with%20Red%20Hat%20Process%20Automation%20Manager" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F11%2F01%2Fspring-boot-enabled-business-process-automation-with-red-hat-process-automation-manager%2F&amp;#38;linkname=Spring%20Boot-enabled%20business%20process%20automation%20with%20Red%20Hat%20Process%20Automation%20Manager" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F11%2F01%2Fspring-boot-enabled-business-process-automation-with-red-hat-process-automation-manager%2F&amp;#38;linkname=Spring%20Boot-enabled%20business%20process%20automation%20with%20Red%20Hat%20Process%20Automation%20Manager" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F11%2F01%2Fspring-boot-enabled-business-process-automation-with-red-hat-process-automation-manager%2F&amp;#38;linkname=Spring%20Boot-enabled%20business%20process%20automation%20with%20Red%20Hat%20Process%20Automation%20Manager" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F11%2F01%2Fspring-boot-enabled-business-process-automation-with-red-hat-process-automation-manager%2F&amp;#38;linkname=Spring%20Boot-enabled%20business%20process%20automation%20with%20Red%20Hat%20Process%20Automation%20Manager" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F11%2F01%2Fspring-boot-enabled-business-process-automation-with-red-hat-process-automation-manager%2F&amp;#38;linkname=Spring%20Boot-enabled%20business%20process%20automation%20with%20Red%20Hat%20Process%20Automation%20Manager" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F11%2F01%2Fspring-boot-enabled-business-process-automation-with-red-hat-process-automation-manager%2F&amp;#38;linkname=Spring%20Boot-enabled%20business%20process%20automation%20with%20Red%20Hat%20Process%20Automation%20Manager" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F11%2F01%2Fspring-boot-enabled-business-process-automation-with-red-hat-process-automation-manager%2F&amp;#38;linkname=Spring%20Boot-enabled%20business%20process%20automation%20with%20Red%20Hat%20Process%20Automation%20Manager" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F11%2F01%2Fspring-boot-enabled-business-process-automation-with-red-hat-process-automation-manager%2F&amp;#38;title=Spring%20Boot-enabled%20business%20process%20automation%20with%20Red%20Hat%20Process%20Automation%20Manager" data-a2a-url="https://developers.redhat.com/blog/2018/11/01/spring-boot-enabled-business-process-automation-with-red-hat-process-automation-manager/" data-a2a-title="Spring Boot-enabled business process automation with Red Hat Process Automation Manager"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/11/01/spring-boot-enabled-business-process-automation-with-red-hat-process-automation-manager/"&gt;Spring Boot-enabled business process automation with Red Hat Process Automation Manager&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/1vJj6lnr8T4" height="1" width="1" alt=""/&gt;</content><summary>With the release of version 7.1 of Red Hat Process Automation Manager (RHPAM), the platform now supports the deployment of the process automation manager runtime as a “capability” within Spring Boot applications. As Maciej Swiderski, the project lead for jBPM.org (the upstream community project for RHPAM) explained earlier this year, the KIE (Knowledge Is Everything) platform on which RHPAM is bui...</summary><dc:creator>Duncan Doyle</dc:creator><dc:date>2018-11-01T12:00:11Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/11/01/spring-boot-enabled-business-process-automation-with-red-hat-process-automation-manager/</feedburner:origLink></entry><entry><title>Native JSON and Node 8.11 baseline in Node.js client 0.6.0!!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Bues0d-vb9I/native-json-and-node-811-baseline-in.html" /><category term="feed_group_name_infinispan" scheme="searchisko:content:tags" /><category term="feed_name_infinispan" scheme="searchisko:content:tags" /><category term="javascript" scheme="searchisko:content:tags" /><category term="Node.js" scheme="searchisko:content:tags" /><category term="release" scheme="searchisko:content:tags" /><author><name>Galder Zamarreño</name></author><id>searchisko:content:id:jbossorg_blog-native_json_and_node_8_11_baseline_in_node_js_client_0_6_0</id><updated>2018-10-31T12:10:29Z</updated><published>2018-10-31T12:10:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;Infinispan Node.js client 0.6.0 is out now!! :)&lt;br /&gt;&lt;br /&gt;As well as updating the client so that it understand the latest Hot Rod protocols in Infinispan 9.4.0.Final, this version comes with native JSON object support.&lt;br /&gt;&lt;br /&gt;To make the Node.js client backwards compatible, the client still treats key/value pairs as String by default. If you want to use native JSON objects, you have to explicitly configure the Node.js client to do so (see &lt;a href="https://github.com/infinispan/js-client#supported-data-types"&gt;example&lt;/a&gt;).&lt;br /&gt;&lt;br /&gt;Starting with this version, we've upgraded the base Node version requirement to 8.11, which is the latest stable release branch at the time of writing. With such upgrade, the client no longer needs to use external promise dependency which was know to &lt;a href="https://issues.jboss.org/browse/HRJS-63"&gt;leak&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;If you're a Node.js user and want to store data remotely in Infinispan server instances, please give the client a go and tell us what you think of it via our &lt;a href="https://developer.jboss.org/en/infinispan/content"&gt;forum&lt;/a&gt;, via our &lt;a href="https://issues.jboss.org/projects/HRJS"&gt;issue tracker&lt;/a&gt; or via &lt;a href="https://zulipchat.com/"&gt;Zulip&lt;/a&gt; on &lt;a href="https://infinispan.zulipchat.com/"&gt;Infinispan channel&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;Cheers&lt;br /&gt;Galder&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/Infinispan/~4/h3t-4fxP20o" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Bues0d-vb9I" height="1" width="1" alt=""/&gt;</content><summary>Infinispan Node.js client 0.6.0 is out now!! :) As well as updating the client so that it understand the latest Hot Rod protocols in Infinispan 9.4.0.Final, this version comes with native JSON object support. To make the Node.js client backwards compatible, the client still treats key/value pairs as String by default. If you want to use native JSON objects, you have to explicitly configure the Nod...</summary><dc:creator>Galder Zamarreño</dc:creator><dc:date>2018-10-31T12:10:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/Infinispan/~3/h3t-4fxP20o/native-json-and-node-811-baseline-in.html</feedburner:origLink></entry><entry><title>Business Process Driven Web Terminal - jBPM Business Apps Demo</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/nfd9xP4XLNU/business-process-driven-web-terminal.html" /><category term="feed_group_name_jbossjbpmcommunity" scheme="searchisko:content:tags" /><category term="feed_name_swiderskimaciej" scheme="searchisko:content:tags" /><author><name>Tihomir Surdilovic</name></author><id>searchisko:content:id:jbossorg_blog-business_process_driven_web_terminal_jbpm_business_apps_demo</id><updated>2018-10-30T16:38:50Z</updated><published>2018-10-30T16:38:00Z</published><content type="html">In this &lt;a href="https://start.jbpm.org/"&gt;jBPM Business Application&lt;/a&gt; demo we show how you can dynamically present your business process data to your users.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-BcvRQzQdGJI/W9iGvw4eMHI/AAAAAAAAhdg/vzldZawJYlY75xgiCfTmO1tT7J9e00p5QCLcBGAs/s1600/Screen%2BShot%2B2018-10-30%2Bat%2B12.41.11%2BPM.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"&gt;&lt;img border="0" data-original-height="733" data-original-width="1600" height="182" src="https://1.bp.blogspot.com/-BcvRQzQdGJI/W9iGvw4eMHI/AAAAAAAAhdg/vzldZawJYlY75xgiCfTmO1tT7J9e00p5QCLcBGAs/s400/Screen%2BShot%2B2018-10-30%2Bat%2B12.41.11%2BPM.png" width="400" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;Demo sample&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="https://github.com/business-applications/sample-websocket-terminal"&gt;The demo app&lt;/a&gt; is a Websocket terminal app where you can enter in different commands and results of those commands are displayed back. Each command entered triggers our demo business process which uses the jBPM Business Rules task to evaluate the command and then passes it on to&lt;br /&gt;the&lt;a href="https://github.com/kiegroup/jbpm-work-items/tree/master/exec-workitem"&gt; jBPM Exec workitem&lt;/a&gt; (or the &lt;a href="https://github.com/kiegroup/jbpm-work-items/tree/master/openweathermap-workitem"&gt;OpenWeatherMap workitem&lt;/a&gt; if weather info is requested).&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/-w3frlStEIuY/W9iHgoGUL9I/AAAAAAAAhdo/j-4-ZvAx5Zk40Pu8G2KhclK2RhjWz3RdwCLcBGAs/s1600/Screen%2BShot%2B2018-10-30%2Bat%2B12.44.41%2BPM.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"&gt;&lt;img border="0" data-original-height="822" data-original-width="1600" height="164" src="https://4.bp.blogspot.com/-w3frlStEIuY/W9iHgoGUL9I/AAAAAAAAhdo/j-4-ZvAx5Zk40Pu8G2KhclK2RhjWz3RdwCLcBGAs/s320/Screen%2BShot%2B2018-10-30%2Bat%2B12.44.41%2BPM.png" width="320" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;Business process used in demo&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;The demo shows off how results of business process execution can dynamically trigger updates of your app UI. It also shows the power of the jBPM Exec workitem which can come really handy in my business app situations.&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;For more details and a walkthrough of this demo app view the youtube video here:&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;iframe width="320" height="266" class="YOUTUBE-iframe-video" data-thumbnail-src="https://i.ytimg.com/vi/-XIb4kk9YS4/0.jpg" src="https://www.youtube.com/embed/-XIb4kk9YS4?feature=player_embedded" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/nfd9xP4XLNU" height="1" width="1" alt=""/&gt;</content><summary>In this jBPM Business Application demo we show how you can dynamically present your business process data to your users. Demo sample The demo app is a Websocket terminal app where you can enter in different commands and results of those commands are displayed back. Each command entered triggers our demo business process which uses the jBPM Business Rules task to evaluate the command and then passe...</summary><dc:creator>Tihomir Surdilovic</dc:creator><dc:date>2018-10-30T16:38:00Z</dc:date><feedburner:origLink>http://mswiderski.blogspot.com/2018/10/business-process-driven-web-terminal.html</feedburner:origLink></entry><entry><title>Analyzing and reducing SystemTap’s startup cost for scripts</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/A3hYBolVnB4/" /><category term="community" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="instrumentation" scheme="searchisko:content:tags" /><category term="performance" scheme="searchisko:content:tags" /><category term="Performance Tuning" scheme="searchisko:content:tags" /><category term="Red Hat Enterprise Linux" scheme="searchisko:content:tags" /><category term="rhel" scheme="searchisko:content:tags" /><category term="systemtap" scheme="searchisko:content:tags" /><author><name>William Cohen</name></author><id>searchisko:content:id:jbossorg_blog-analyzing_and_reducing_systemtap_s_startup_cost_for_scripts</id><updated>2018-10-30T14:41:27Z</updated><published>2018-10-30T14:41:27Z</published><content type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/blog/tag/systemtap/"&gt;SystemTap&lt;/a&gt; is a powerful tool for investigating system issues, but for some SystemTap instrumentation scripts, the startup times are too long. This article describes how to analyze and reduce SystemTap&amp;#8217;s startup costs for scripts.&lt;/p&gt; &lt;p&gt;We can use SystemTap to investigate this problem and provide some hard data on the time required for each of the passes that SystemTap uses to convert a SystemTap script into instrumentation. SystemTap has a set of probe points marking the start and end of passes from 0 to 5:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;pass0: Parsing command-line arguments&lt;/li&gt; &lt;li&gt;pass1: Parsing scripts&lt;/li&gt; &lt;li&gt;pass2: Elaboration&lt;/li&gt; &lt;li&gt;pass3: Translation to C&lt;/li&gt; &lt;li&gt;pass4: Compilation of C code into kernel module&lt;/li&gt; &lt;li&gt;pass5: Running the instrumentation&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;span id="more-524657"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Analyzing startup costs&lt;/h2&gt; &lt;p&gt;Since we are interested in the time required to the point where the script is actually collecting data, we are not going to collect data on pass5. Each of the probe points for the start and end of a pass includes an argument to a C++ structure describing the session. The session structure includes information about the script name, which is useful for identifying which scripts have high startup overhead. The SystemTap example script &lt;a href="https://sourceware.org/systemtap/examples/#apps/stap_time.stp"&gt;stap_time.stp&lt;/a&gt; was developed to record this information. Because there are differences in how &lt;a href="https://developers.redhat.com/products/rhel/download/"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL) 7 stores C++ strings, the script has been slightly modified to the following:&lt;/p&gt; &lt;pre&gt;#! /usr/bin/env stap # Copyright (C) 2018 Red Hat, Inc. # Written by William Cohen &amp;#60;wcohen@redhat.com&amp;#62; # # Provide concise plottable information about phases 0-4 of systemtap global start, pass0, pass1, pass2, pass3, pass4 function print_head() {printf("")} function print_tail() {printf("")} probe begin { print_head() } probe end { print_tail() } probe stap.pass0 { start[session] = gettimeofday_ms() } probe stap.pass0.end { pass0[session] = gettimeofday_ms() } probe stap.pass1.end { pass1[session] = gettimeofday_ms() } probe stap.pass2.end { pass2[session] = gettimeofday_ms() } probe stap.pass3.end { pass3[session] = gettimeofday_ms() } probe stap.pass4.end { pass4[session] = gettimeofday_ms() // Dig through C++ string private fields to find the systemtap script name cmdline_script = @cast(session, "struct systemtap_session")-&amp;#62;cmdline_script-&amp;#62;_M_dataplus-&amp;#62;_M_p if (strlen(user_string2(cmdline_script, "&amp;#60;unavailable&amp;#62;"))){ script = "&amp;#60;cmdline_script&amp;#62;" } else { script_file = @cast(session, "struct systemtap_session")-&amp;#62;script_file-&amp;#62;_M_dataplus-&amp;#62;_M_p script = user_string2(script_file, "&amp;#60;unavailable&amp;#62;") } // print out data printf("%s %d %d %d %d %d\n", script, pass0[session] - start[session], pass1[session] - pass0[session], pass2[session] - pass1[session], pass3[session] - pass2[session], pass4[session] - pass3[session]) // delete entries delete pass0[session] delete pass1[session] delete pass2[session] delete pass3[session] delete pass4[session] } &lt;/pre&gt; &lt;p&gt;When the script is running, each time SystemTap runs and completes pass4, it prints out a line that shows the script name followed by the time required in milliseconds for each pass (0 through 4), similar to the following:&lt;/p&gt; &lt;pre&gt;also_ran.stp 71 1721 1440 80 2245&lt;/pre&gt; &lt;p&gt;Because the SystemTap scripts are part of SystemTap &lt;code&gt;testsuite&lt;/code&gt;, it becomes very easy to collect data on all of the examples by running the following in a terminal window:&lt;/p&gt; &lt;pre&gt;$ stap stap_time &amp;#62; syscall_any.dat&lt;/pre&gt; &lt;p&gt;Then, in another terminal window, in &lt;code&gt;/usr/share/systemtap/testsuite&lt;/code&gt;, run the following as root:&lt;/p&gt; &lt;pre&gt;make installcheck RUNTESTFLAGS="--debug systemtap.examples/check.exp"&lt;/pre&gt; &lt;p&gt;Once &lt;code&gt;testsuite&lt;/code&gt; completes, the &lt;code&gt;syscall_any.dat&lt;/code&gt; file contains data about how long each of the phases of the example scripts took to complete. A Gnuplot can be made of that data with the following &lt;code&gt;syscall_any.gp&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;set terminal png set output 'syscall_any.png' set key left top invert set title 'Systemtap Examples Times with syscall\_any tapset' set grid y set style data histograms set style histogram rowstacked set ytics 10 nomirror set style fill solid 1 set ylabel "Time (ms)" set ytics 10000 set xlabel "Example script" set xrange [0:] set yrange [0:] plot 'syscall_any.dat' using 2 t "Pass 0 (cmdline parsing)", '' using 3 t "Pass 1 (script parsing)", '' using 4 t "Pass 2 (elaboration)", '' using 5 t "Pass 3 (code generation)", '' using 6 t "Pass 4 (module compilation)",&lt;/pre&gt; &lt;p&gt;Now we have a bar graph that summarizes how long SystemTap took to convert the various example scripts into actual instrumentation. The graph looks like the following:&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/syscall_any.png"&gt;&lt;img class=" aligncenter wp-image-528367 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/10/syscall_any.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/syscall_any.png" alt="Bar graph showing how long SystemTap took to convert example script to instrumentation with syscall_any tapset" width="640" height="480" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/syscall_any.png 640w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/syscall_any-300x225.png 300w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The first thing that stands out is the peak at 243 (&lt;code&gt;strace.stp&lt;/code&gt;) is approaching 90 seconds of overhead to start. The &lt;code&gt;strace.stp&lt;/code&gt; script instruments every &lt;code&gt;syscall&lt;/code&gt; entry and exit, resulting in a large number of probes and associated code for those probes. The peak at 195–196 for &lt;code&gt;errsnoop.stp&lt;/code&gt; also has the same cause.&lt;/p&gt; &lt;p&gt;The peak at 203 is due to &lt;code&gt;ltrace.stp&lt;/code&gt; instrumenting many functions in the shared libraries used by the monitored user-space application. This creates instrumentation for 545 probe points.&lt;/p&gt; &lt;p&gt;The peaks toward the right of the graph at 300 and 301 are for &lt;code&gt;qemu_count.stp&lt;/code&gt; and are caused by using SystemTap wildcards to instrument all the QEMU probe points. On the x86_64 RHEL machine that the measurements were being made on, there were over 10,000 probe points being instrumented because of QEMU emulation for many different processors installed on the machine, such as SPARC, MIPS, and PowerPC processors.&lt;/p&gt; &lt;p&gt;The peaks at 122 to 125 for &lt;code&gt;hw_watch_addr.stp&lt;/code&gt; and &lt;code&gt;hw_watch_sym.stp&lt;/code&gt; and at 264 to 267 for &lt;code&gt;ioctl_handler.stp&lt;/code&gt; and &lt;code&gt;latencytap.stp&lt;/code&gt; are unusual, as they spent more time in code generation (pass3) than most scripts. This is because these scripts are being generated with the SystemTap &lt;code&gt;--all-modules&lt;/code&gt; option, which pulls more debugging information into the instrumentation to allow the script to map addresses for modules back to function names.&lt;/p&gt; &lt;h2&gt;Reducing startup costs&lt;/h2&gt; &lt;p&gt;Reducing the startup overhead for the example scripts is a work in progress, but there have been some improvements over the past month for several of the scripts that instrument each &lt;code&gt;syscall&lt;/code&gt;. The &lt;code&gt;syscall_any&lt;/code&gt; and &lt;code&gt;syscall_any.return&lt;/code&gt; probe points are available in the newly released SystemTap 4.0, which will be discussed in an upcoming Red Hat Developer article.&lt;/p&gt; &lt;p&gt;Below is a graph of the example script times with the patches implementing &lt;code&gt;syscall_any&lt;/code&gt; removed. There are peaks in the graph below at 17 (&lt;code&gt;eventcount.stp&lt;/code&gt;), 40 (&lt;code&gt;stopwatches.stp&lt;/code&gt;), 111 (&lt;code&gt;syscallbypid-nd.stp&lt;/code&gt;), 250 (&lt;code&gt;thread-business.stp&lt;/code&gt;), 255 (&lt;code&gt;container_check.stp&lt;/code&gt;), and 256 (&lt;code&gt;errno.stp&lt;/code&gt;) that are not in the graph above, which used the &lt;code&gt;syscall_any&lt;/code&gt; tapset.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/no_syscall_any.png"&gt;&lt;img class=" aligncenter wp-image-528377 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/10/no_syscall_any.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/no_syscall_any.png" alt="Bar graph showing how long SystemTap took to convert example scripts to instrumentation without syscall_any tapset" width="640" height="480" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/no_syscall_any.png 640w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/no_syscall_any-300x225.png 300w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;This simple graphing of the example script startup times gives us a quick indication of the overhead for the various example scripts and some visual clues of what phases of the instrumentation generation are more costly.&lt;/p&gt; &lt;h2&gt;Additional resources&lt;/h2&gt; &lt;p&gt;See &lt;a href="https://developers.redhat.com/blog/author/wcohen2013/"&gt;my other  articles&lt;/a&gt; on Red Hat Developers:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/05/14/making-the-operation-of-code-more-transparent-and-obvious/"&gt;Making the Operation of Code More Transparent and Obvious with SystemTap&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/05/11/use-the-dynamic-tracing-tools-luke/"&gt;Use the dynamic tracing tools, Luke&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2017/02/16/find-what-capabilities-an-application-requires-to-successful-run-in-a-container/"&gt;Find what capabilities an application requires to successfully run in a container&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2016/06/01/how-to-avoid-wasting-megabytes-of-memory-a-few-bytes-at-a-time/"&gt;How to avoid wasting megabytes of memory a few bytes at a time&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2016/05/04/instruction-level-multithreading-to-improve-processor-utilization/"&gt;Instruction-level Multithreading to improve processor utilization&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2016/04/06/dont-cross-the-streams-thread-safety-and-memory-accesses-at-the-speed-of-light-2/" rel="bookmark"&gt;“Don’t cross the streams”: Thread safety and memory accesses at the speed of light&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Red Hat Developer has many other articles on &lt;a href="https://developers.redhat.com/blog/tag/systemtap/"&gt;SystemTap&lt;/a&gt; and &lt;a href="https://developers.redhat.com/blog/category/performance/"&gt;performance&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F30%2Fanalyzing-reducing-systemtaps-startup-cost%2F&amp;#38;linkname=Analyzing%20and%20reducing%20SystemTap%E2%80%99s%20startup%20cost%20for%20scripts" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F30%2Fanalyzing-reducing-systemtaps-startup-cost%2F&amp;#38;linkname=Analyzing%20and%20reducing%20SystemTap%E2%80%99s%20startup%20cost%20for%20scripts" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F30%2Fanalyzing-reducing-systemtaps-startup-cost%2F&amp;#38;linkname=Analyzing%20and%20reducing%20SystemTap%E2%80%99s%20startup%20cost%20for%20scripts" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F30%2Fanalyzing-reducing-systemtaps-startup-cost%2F&amp;#38;linkname=Analyzing%20and%20reducing%20SystemTap%E2%80%99s%20startup%20cost%20for%20scripts" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F30%2Fanalyzing-reducing-systemtaps-startup-cost%2F&amp;#38;linkname=Analyzing%20and%20reducing%20SystemTap%E2%80%99s%20startup%20cost%20for%20scripts" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F30%2Fanalyzing-reducing-systemtaps-startup-cost%2F&amp;#38;linkname=Analyzing%20and%20reducing%20SystemTap%E2%80%99s%20startup%20cost%20for%20scripts" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F30%2Fanalyzing-reducing-systemtaps-startup-cost%2F&amp;#38;linkname=Analyzing%20and%20reducing%20SystemTap%E2%80%99s%20startup%20cost%20for%20scripts" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F30%2Fanalyzing-reducing-systemtaps-startup-cost%2F&amp;#38;linkname=Analyzing%20and%20reducing%20SystemTap%E2%80%99s%20startup%20cost%20for%20scripts" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F30%2Fanalyzing-reducing-systemtaps-startup-cost%2F&amp;#38;title=Analyzing%20and%20reducing%20SystemTap%E2%80%99s%20startup%20cost%20for%20scripts" data-a2a-url="https://developers.redhat.com/blog/2018/10/30/analyzing-reducing-systemtaps-startup-cost/" data-a2a-title="Analyzing and reducing SystemTap’s startup cost for scripts"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/10/30/analyzing-reducing-systemtaps-startup-cost/"&gt;Analyzing and reducing SystemTap&amp;#8217;s startup cost for scripts&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/A3hYBolVnB4" height="1" width="1" alt=""/&gt;</content><summary>SystemTap is a powerful tool for investigating system issues, but for some SystemTap instrumentation scripts, the startup times are too long. This article describes how to analyze and reduce SystemTap’s startup costs for scripts. We can use SystemTap to investigate this problem and provide some hard data on the time required for each of the passes that SystemTap uses to convert a SystemTap script ...</summary><dc:creator>William Cohen</dc:creator><dc:date>2018-10-30T14:41:27Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/10/30/analyzing-reducing-systemtaps-startup-cost/</feedburner:origLink></entry><entry><title>Codemotion Amsterdam - Sharing pitfalls everyone should avoid</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/NJA01wurOVQ/codemotion-amsterdam-sharing-3-pitfalls.html" /><category term="AppDev" scheme="searchisko:content:tags" /><category term="best practices" scheme="searchisko:content:tags" /><category term="cloud" scheme="searchisko:content:tags" /><category term="conference" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="FUSE" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-codemotion_amsterdam_sharing_pitfalls_everyone_should_avoid</id><updated>2018-11-01T15:06:23Z</updated><published>2018-10-30T06:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/-7-Sm7R3_MX4/W9sURXozE6I/AAAAAAAAtPU/2rhhN_4Zpj4LOACAmFWGD7OfGvKF9zIGACLcBGAs/s1600/Screenshot%2B2018-11-01%2Bat%2B15.06.24.png" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"&gt;&lt;img alt="codemotion amsterdam" border="0" data-original-height="879" data-original-width="1600" height="175" src="https://4.bp.blogspot.com/-7-Sm7R3_MX4/W9sURXozE6I/AAAAAAAAtPU/2rhhN_4Zpj4LOACAmFWGD7OfGvKF9zIGACLcBGAs/s320/Screenshot%2B2018-11-01%2Bat%2B15.06.24.png" title="" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;One of the really interesting and global conference is Codemotion. I've been lucky enough to speak at three different version in Europe.&lt;br /&gt;&lt;br /&gt;This year, together with &lt;a href="https://twitter.com/roelhodzelmans" target="_blank"&gt;Roel Hodzelmans&lt;/a&gt;, we're targeting the Amsterdam conference and going all in with three of our sessions around the popular '3 Pitfalls' series.&lt;br /&gt;&lt;br /&gt;First, the popular session revealing the 3 pitfalls everyone should avoid with hybrid multicloud. Second, we dig deeper based on popular demand to provide you with 3 more pitfalls everyone should avoid with hybrid multicloud. Finally, we are expanding the scope to dive into 3 pitfalls everyone should avoid with microservices.&lt;br /&gt;&lt;br /&gt;All three bring real life customer experience from our daily interactions and share these in the interest of collaboration and learning. Check out the abstracts for all three talks below.&lt;br /&gt;&lt;br /&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;h3 style="line-height: 1.38; margin-bottom: 16pt; margin-top: 0pt; text-align: left;"&gt;&lt;span style="background-color: transparent; color: #666666; font-family: Arial; font-size: 15pt; font-style: normal; font-variant-caps: normal; font-variant-east-asian: normal; font-variant-ligatures: normal; font-variant-position: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;"&gt;3 Pitfalls Everyone Should Avoid with Hybrid Multicloud&lt;/span&gt;&lt;/h3&gt;&lt;div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;"&gt;&lt;span style="background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-variant-caps: normal; font-variant-east-asian: normal; font-variant-ligatures: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;"&gt;&lt;i&gt;The daily hype is all around you. From cloud, hybrid cloud, to hybrid multicloud, you’re told this is the way to ensure a digital future for your business. These choices you’ve got to make don’t preclude the daily work of enhancing your customer’s experience and agile delivery of those applications. Let us take you on a journey, looking closely at what hybrid multi-cloud means for your business, the decisions being made about delivering applications, and dealing with legacy applications, likely the most important resources to your business. Join us for an hour of power, where real customer experiences are used to highlight the three top lessons learned as they transitioned into hybrid multi-cloud environments.&lt;/i&gt;&lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;b style="-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; caret-color: rgb(0, 0, 0); color: black; font-family: -webkit-standard; font-style: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: auto; text-align: start; text-decoration: none; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px;"&gt;&lt;br /&gt;&lt;/b&gt;&lt;h3 style="line-height: 1.38; margin-bottom: 16pt; margin-top: 0pt; text-align: left;"&gt;&lt;span style="background-color: transparent; color: #666666; font-family: Arial; font-size: 15pt; font-style: normal; font-variant-caps: normal; font-variant-east-asian: normal; font-variant-ligatures: normal; font-variant-position: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;"&gt;3 More Pitfalls Everyone Should Avoid with Hybrid Multicloud&lt;/span&gt;&lt;/h3&gt;&lt;div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;"&gt;&lt;span style="background-color: transparent; font-variant-east-asian: normal; vertical-align: baseline;"&gt;&lt;i&gt;&lt;span style="font-family: Arial;"&gt;&lt;span style="font-size: 11pt; white-space: pre-wrap;"&gt;Back by popular demand, this session builds on the original ‘3 Pitfalls Everyone Should Avoid with Hybrid Multicloud’ and brings three new revelations from real customer experiences. From cloud, hybrid cloud, to hybrid multicloud you’ve been told it’s the path to a digitally successful future for your &lt;/span&gt;&lt;span style="font-size: 14.6667px; white-space: pre-wrap;"&gt;organisation&lt;/span&gt;&lt;span style="font-size: 11pt; white-space: pre-wrap;"&gt;. In the first session we shared a journey through hybrid multicloud pitfalls that just scratched the surface. Let’s take another look at a few more pitfalls that are found on the road to hybrid multicloud for your business as you’re delivering applications, dealing with legacy applications and making important decisions for your cloud strategies. Join us for three more lessons learned from real life transitions into hybrid multicloud environments.&lt;/span&gt;&lt;/span&gt;&lt;/i&gt;&lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;b style="-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; caret-color: rgb(0, 0, 0); color: black; font-family: -webkit-standard; font-style: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: auto; text-align: start; text-decoration: none; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px;"&gt;&lt;br /&gt;&lt;/b&gt;&lt;h3 style="line-height: 1.38; margin-bottom: 16pt; margin-top: 0pt; text-align: left;"&gt;&lt;span style="background-color: transparent; color: #666666; font-family: Arial; font-size: 15pt; font-style: normal; font-variant-caps: normal; font-variant-east-asian: normal; font-variant-ligatures: normal; font-variant-position: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;"&gt;3 Pitfalls Everyone Should Avoid with Microservices&lt;/span&gt;&lt;/h3&gt;&lt;div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;"&gt;&lt;span style="background-color: transparent; font-variant-east-asian: normal; vertical-align: baseline;"&gt;&lt;i&gt;&lt;span style="font-family: Arial;"&gt;&lt;span style="font-size: 11pt; white-space: pre-wrap;"&gt;The daily hype is all around you. MIcroservices are a necessary step along the path to integration for a digitally successful future for your &lt;/span&gt;&lt;span style="font-size: 14.6667px; white-space: pre-wrap;"&gt;organisation&lt;/span&gt;&lt;span style="font-size: 11pt; white-space: pre-wrap;"&gt;. The choices you’ve got to make don’t preclude the daily work of enhancing your customer’s experiences. From containers, cloud, multicloud, and beyond, microservices are the core infrastructure ensuring your &lt;/span&gt;&lt;span style="font-size: 14.6667px; white-space: pre-wrap;"&gt;organisation's&lt;/span&gt;&lt;span style="font-size: 11pt; white-space: pre-wrap;"&gt; flexibility in the digital world. Join us for an hour of power, where real customer experiences are used to highlight the three top lessons as they transitioned their integration infrastructure into modern day microservices.&lt;/span&gt;&lt;/span&gt;&lt;/i&gt;&lt;/span&gt;&lt;/div&gt;&lt;div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;"&gt;&lt;span style="background-color: transparent; font-variant-east-asian: normal; vertical-align: baseline;"&gt;&lt;i&gt;&lt;span style="font-family: Arial;"&gt;&lt;span style="font-size: 11pt; white-space: pre-wrap;"&gt;&lt;br /&gt;&lt;/span&gt;&lt;/span&gt;&lt;/i&gt;&lt;/span&gt;&lt;/div&gt;&lt;div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;"&gt;&lt;span style="background-color: transparent; font-variant-east-asian: normal; vertical-align: baseline;"&gt;&lt;span style="font-family: Arial;"&gt;&lt;span style="font-size: 11pt; white-space: pre-wrap;"&gt;Hope to see you there!&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=u6ddXzZYSdg:si7hKJoXBKc:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=u6ddXzZYSdg:si7hKJoXBKc:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=u6ddXzZYSdg:si7hKJoXBKc:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=u6ddXzZYSdg:si7hKJoXBKc:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=u6ddXzZYSdg:si7hKJoXBKc:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=u6ddXzZYSdg:si7hKJoXBKc:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=u6ddXzZYSdg:si7hKJoXBKc:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=u6ddXzZYSdg:si7hKJoXBKc:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=u6ddXzZYSdg:si7hKJoXBKc:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=u6ddXzZYSdg:si7hKJoXBKc:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=u6ddXzZYSdg:si7hKJoXBKc:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/u6ddXzZYSdg" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/NJA01wurOVQ" height="1" width="1" alt=""/&gt;</content><summary>One of the really interesting and global conference is Codemotion. I've been lucky enough to speak at three different version in Europe. This year, together with Roel Hodzelmans, we're targeting the Amsterdam conference and going all in with three of our sessions around the popular '3 Pitfalls' series. First, the popular session revealing the 3 pitfalls everyone should avoid with hybrid multicloud...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2018-10-30T06:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/u6ddXzZYSdg/codemotion-amsterdam-sharing-3-pitfalls.html</feedburner:origLink></entry><entry><title>Hibernate OGM 5.4.0.Final release</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ASPyZhCb6c4/" /><category term="feed_group_name_hibernate" scheme="searchisko:content:tags" /><category term="feed_name_inrelationto" scheme="searchisko:content:tags" /><category term="hibernate ogm" scheme="searchisko:content:tags" /><category term="releases" scheme="searchisko:content:tags" /><author><name>Davide D'Alto</name></author><id>searchisko:content:id:jbossorg_blog-hibernate_ogm_5_4_0_final_release</id><updated>2018-10-30T11:09:17Z</updated><published>2018-10-30T00:00:00Z</published><content type="html">&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;&lt;a href="http://hibernate.org/ogm/releases/5.4/#get-it"&gt;Hibernate OGM 5.4.0.Final&lt;/a&gt; has been released!&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Here’s a list of the main changes compared to version &lt;a href="http://in.relation.to/2018/03/29/hibernate-ogm-5-3-1-Final-released/"&gt;5.3.1.Final&lt;/a&gt;:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Infinispan remote &lt;a href="https://docs.jboss.org/hibernate/ogm/5.4/reference/en-US/html_single/#infinispan-remote-transaction"&gt;transactions over HotRod&lt;/a&gt; client&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://docs.jboss.org/hibernate/ogm/5.4/reference/en-US/html_single/#_remote_query_capabilities"&gt;JPQL and native queries&lt;/a&gt; support for Infinispan remote&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://docs.jboss.org/hibernate/ogm/5.4/reference/en-US/html_single/#_infinispan_remote_stored_procedures"&gt;server side procedures calls&lt;/a&gt; for Infinispan Remote&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Cache creation and configuration for &lt;a href="https://docs.jboss.org/hibernate/ogm/5.4/reference/en-US/html_single/#infinispan-remote-cache-configuration"&gt;Infinispan remote&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Java types &lt;code&gt;java.time.LocalDate&lt;/code&gt;, &lt;code&gt;java.time.LocalDateTime&lt;/code&gt; and &lt;code&gt;java.time.LocalTime&lt;/code&gt; are natively supported as field types&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://docs.jboss.org/hibernate/ogm/5.4/reference/en-US/html_single/#mongodb-gridfs-support"&gt;GridFS support for MongoDB&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Neo4j remote procedures support via JPA&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;More details available in the &lt;a href="https://hibernate.atlassian.net/secure/ReleaseNote.jspa?projectId=10160&amp;amp;version=31724"&gt;release notes&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="components-upgrade"&gt;&lt;a class="anchor" href="#components-upgrade"&gt;&lt;/a&gt;Components upgrade&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Hibernate ORM 5.3.4.Final&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Hibernate Search 5.10.4.Final&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Infinispan 9.4.0.Final&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Neo4j 3.4.9&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="where-can-i-get-hibernate-ogm"&gt;&lt;a class="anchor" href="#where-can-i-get-hibernate-ogm"&gt;&lt;/a&gt;Where can I get Hibernate OGM?&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;You can include the dialect of your choice in your project using the following Maven coordinates:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://infinispan.org"&gt;Infinispan&lt;/a&gt;&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Remote: &lt;em&gt;org.hibernate.ogm:hibernate-ogm-infinispan-remote:5.4.0.Final&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Embedded: &lt;em&gt;org.hibernate.ogm:hibernate-ogm-infinispan-embedded:5.4.0.Final&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.mongodb.com"&gt;MongoDB&lt;/a&gt;: &lt;em&gt;org.hibernate.ogm:hibernate-ogm-mongodb:5.4.0.Final&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://neo4j.com"&gt;Neo4j&lt;/a&gt;: &lt;em&gt;org.hibernate.ogm:hibernate-ogm-neo4j:5.4.0.Final&lt;/em&gt;&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Infinispan Remote: &lt;em&gt;org.hibernate.ogm:hibernate-ogm-featurepack-infinispan-remote:5.4.0.Final&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Infinispan Embedded: &lt;em&gt;org.hibernate.ogm:hibernate-ogm-featurepack-infinispan-embedded:5.4.0.Final&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;MongoDB: &lt;em&gt;org.hibernate.ogm:hibernate-ogm-featurepack-mongodb:5.4.0.Final&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Neo4j: &lt;em&gt;org.hibernate.ogm:hibernate-ogm-featurepack-neo4j:5.4.0.Final&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Alternatively, you can download archives containing all the binaries, source code and documentation &lt;a href="https://sourceforge.net/projects/hibernate/files/hibernate-ogm/5.4.0.Final"&gt;from Sourceforge&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;If you are interested about available versions, you can check the official &lt;a href="http://hibernate.org/ogm/releases"&gt;Hibernate OGM download page&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="how-can-i-get-in-touch"&gt;&lt;a class="anchor" href="#how-can-i-get-in-touch"&gt;&lt;/a&gt;How can I get in touch?&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;You can find us through the following channels:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/c/hibernate-ogm"&gt;User forum&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://hibernate.atlassian.net/browse/OGM"&gt;Issue tracker&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://lists.jboss.org/pipermail/hibernate-dev/"&gt;Mailing list&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://stackoverflow.com"&gt;Stack Overflow&lt;/a&gt;: we monitor the tag &lt;em&gt;hibernate-ogm&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.hipchat.com/gXEjW5Wgg"&gt;HipChat&lt;/a&gt;: Hibernate OGM hipchat room&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="contributions"&gt;&lt;a class="anchor" href="#contributions"&gt;&lt;/a&gt;Contributions&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Thanks a lot to our contributors (in order of appearance in the commit log): Anastasiia Gavrilash, Aleksandr Mylnikov, Volodymyr Trytsetskyi, The Viet Nguyen and Sergey Chernolyas.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Without them, Hibernate OGM 5.4 Final wouldn’t have some of the new features we were able to include. You rock!&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Looking forward to hearing your feedback!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ASPyZhCb6c4" height="1" width="1" alt=""/&gt;</content><summary>Hibernate OGM 5.4.0.Final has been released! Here’s a list of the main changes compared to version 5.3.1.Final: Infinispan remote transactions over HotRod client JPQL and native queries support for Infinispan remote server side procedures calls for Infinispan Remote Cache creation and configuration for Infinispan remote Java types java.time.LocalDate, java.time.LocalDateTime and java.time.LocalTim...</summary><dc:creator>Davide D'Alto</dc:creator><dc:date>2018-10-30T00:00:00Z</dc:date><feedburner:origLink>http://in.relation.to/2018/10/30/hibernate-ogm-5-4-Final-released/</feedburner:origLink></entry><entry><title>How to run Kafka on Openshift, the enterprise Kubernetes, with AMQ Streams</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/SLzpc6LTvW0/" /><category term="Apache Kafka" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="integration" scheme="searchisko:content:tags" /><category term="jboss a-mq" scheme="searchisko:content:tags" /><category term="microservices" scheme="searchisko:content:tags" /><category term="Modern App Dev" scheme="searchisko:content:tags" /><category term="Red Hat AMQ" scheme="searchisko:content:tags" /><category term="Red Hat AMQ Streams" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Container Platform" scheme="searchisko:content:tags" /><category term="Stream Processing" scheme="searchisko:content:tags" /><author><name>Hugo Guerrero</name></author><id>searchisko:content:id:jbossorg_blog-how_to_run_kafka_on_openshift_the_enterprise_kubernetes_with_amq_streams</id><updated>2018-10-29T11:00:53Z</updated><published>2018-10-29T11:00:53Z</published><content type="html">&lt;p&gt;&lt;span style="font-weight: 400;"&gt;On October 25th Red Hat &lt;/span&gt;&lt;a href="https://access.redhat.com/announcements/3667151"&gt;&lt;span style="font-weight: 400;"&gt;announced&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; the general availability of their AMQ Streams Kubernetes Operator for Apache Kafka. &lt;/span&gt;&lt;a href="https://access.redhat.com/products/red-hat-amq-streams"&gt;&lt;span style="font-weight: 400;"&gt;Red Hat AMQ Streams&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; focuses on running Apache Kafka on Openshift providing a massively-scalable, distributed, and high performance data streaming platform. AMQ Streams, based on the Apache Kafka and &lt;/span&gt;&lt;a href="http://strimzi.io/"&gt;&lt;span style="font-weight: 400;"&gt;Strimzi&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; projects, offers a distributed backbone that allows &lt;a href="https://developers.redhat.com/topics/microservices/"&gt;microservices&lt;/a&gt; and other applications to share data with extremely high throughput. This backbone enables:&lt;/span&gt;&lt;/p&gt; &lt;ul&gt; &lt;li style="font-weight: 400;"&gt;&lt;b&gt;Publish and subscribe:&lt;/b&gt;&lt;span style="font-weight: 400;"&gt; Many to many dissemination in a fault tolerant, durable manner.&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400;"&gt;&lt;b&gt;Replayable events:&lt;/b&gt;&lt;span style="font-weight: 400;"&gt; Serves as a repository for microservices to build in-memory copies of source data, up to any point in time.&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400;"&gt;&lt;b&gt;Long-term data retention:&lt;/b&gt;&lt;span style="font-weight: 400;"&gt; Efficiently stores data for immediate access in a manner limited only by disk space.&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400;"&gt;&lt;b&gt;Partition messages for more horizontal scalability:&lt;/b&gt;&lt;span style="font-weight: 400;"&gt; Allows for organizing messages to maximum concurrent access.&lt;/span&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;One of the most requested items from developers and architects is how to get started with a simple deployment option for testing purposes. In this guide we will use &lt;a href="https://developers.redhat.com/products/cdk/overview/"&gt;Red Hat Container Development Kit&lt;/a&gt;, based on minishift, to start an Apache Kafka cluster on &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt;.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span id="more-531487"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;To set up a Kafka cluster on Openshift from scratch follow the next steps:&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;&lt;span style="font-weight: 400;"&gt;Setup Red Hat Container Development Kit (CDK)&lt;/span&gt;&lt;/h2&gt; &lt;ol&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;Setup  CDK (minishift) on your laptop if you haven’t done that before.&lt;/span&gt; &lt;ol&gt; &lt;li style="font-weight: 400;"&gt;&lt;a href="https://developers.redhat.com/products/cdk/download/"&gt;&lt;span style="font-weight: 400;"&gt;Download CDK&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt;. &lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;Follow the &lt;/span&gt;&lt;a href="https://developers.redhat.com/products/cdk/hello-world"&gt;&lt;span style="font-weight: 400;"&gt;Hello World&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; to install and configure CDK.&lt;/span&gt;&lt;/li&gt; &lt;/ol&gt; &lt;/li&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;The latest version of CDK leverages the concept of profiles, so we will using them to avoid changing other configurations. Create a new &lt;code&gt;streams&lt;/code&gt; profile:&lt;/span&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p style="padding-left: 30px;"&gt;&lt;span style="font-weight: 400;"&gt;&lt;code&gt;$ minishift profile set streams&lt;/code&gt;&lt;/span&gt;&lt;/p&gt; &lt;ol start="3"&gt; &lt;li&gt;&lt;span style="font-weight: 400;"&gt; Configure the system requirements (we recommend 8GB and at least 2 vCPUs available to run smoothly) in this new profile:&lt;/span&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p style="padding-left: 30px;"&gt;&lt;span style="font-weight: 400;"&gt;&lt;code&gt;$ minishift config set cpus 2&lt;/code&gt;&lt;br /&gt; &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;&lt;code&gt;$ minishift config set memory 8192&lt;/code&gt;&lt;/span&gt;&lt;/p&gt; &lt;ol start="4"&gt; &lt;li&gt;&lt;span style="font-weight: 400;"&gt; In my case I use VirtualBox as the VM driver, substitute whichever hypervisor you are using:&lt;/span&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p style="padding-left: 30px;"&gt;&lt;span style="font-weight: 400;"&gt;&lt;code&gt;$ minishift config set vm-driver virtualbox&lt;/code&gt;&lt;/span&gt;&lt;/p&gt; &lt;ol start="5"&gt; &lt;li&gt;&lt;span style="font-weight: 400;"&gt; Because of the Zookeeper dependencies on users, we will need to remove the anyuid add-on that comes out-of-the-box for CDK:&lt;/span&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p style="padding-left: 30px;"&gt;&lt;span style="font-weight: 400;"&gt;&lt;code&gt;$ minishift addons disable anyuid&lt;/code&gt;&lt;/span&gt;&lt;/p&gt; &lt;p style="padding-left: 30px;"&gt;&lt;b&gt;NOTE: This is a CRITICAL step if you are running CDK. If the add-on is not disabled you&amp;#8217;ll get an error when trying to start the Zookeeper TLS sidecar.&lt;/b&gt;&lt;/p&gt; &lt;ol start="6"&gt; &lt;li&gt;&lt;span style="font-weight: 400;"&gt; Start the CDK environment&lt;/span&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p style="padding-left: 30px;"&gt;&lt;span style="font-weight: 400;"&gt;&lt;code&gt;$ minishift start&lt;/code&gt;&lt;/span&gt;&lt;/p&gt; &lt;p style="padding-left: 30px;"&gt;&lt;span style="font-weight: 400;"&gt;You will see the following output if everything worked fine:&lt;/span&gt;&lt;/p&gt; &lt;pre style="padding-left: 30px;"&gt;&lt;span style="font-weight: 400;"&gt;OpenShift server started.&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;The server is accessible via web console at:&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;    https://192.168.99.100:8443&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;You are logged in as:&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;    User:     developer&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;    Password: &amp;#60;any value&amp;#62;&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;To login as administrator:&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;    oc login -u system:admin&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;-- Applying addon 'xpaas':..&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;XPaaS imagestream and templates for OpenShift installed&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;See https://github.com/openshift/openshift-ansible/tree/release-3.10/roles/openshift_examples/files/examples/v3.10&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;-- Applying addon 'admin-user':..&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;-- Exporting of OpenShift images is occuring in background process with pid 35470.&lt;/span&gt;&lt;/pre&gt; &lt;h2&gt;&lt;span style="font-weight: 400;"&gt;Setup AMQ Streams &lt;/span&gt;&lt;/h2&gt; &lt;ol&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;&lt;a href="https://access.redhat.com/node/3667151/423/0"&gt;Download the Red Hat AMQ Streams installation&lt;/a&gt; and example resources from the &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;Red Hat Customer Portal&lt;/span&gt;&lt;span style="font-weight: 400;"&gt;.&lt;/span&gt;&lt;/li&gt; &lt;li&gt;&lt;span style="font-weight: 400;"&gt;Navigate to the unzipped folder to get access to the yaml files&lt;/span&gt;&lt;/li&gt; &lt;li&gt;&lt;span style="font-weight: 400;"&gt;Unzip the downloaded &lt;code&gt;install_and_examples_0.zip&lt;/code&gt; file.&lt;/span&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p style="padding-left: 30px;"&gt;&lt;span style="font-weight: 400;"&gt;&lt;code&gt;$ cd &amp;#60;your_download_folder&amp;#62;/install_and_examples_0&lt;/code&gt;&lt;/span&gt;&lt;/p&gt; &lt;ol start="2"&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;Login in to the OpenShift cluster with admin privileges:&lt;/span&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p style="padding-left: 30px;"&gt;&lt;span style="font-weight: 400;"&gt;&lt;code&gt;$ oc login -u system:admin&lt;/code&gt;&lt;/span&gt;&lt;/p&gt; &lt;ol start="3"&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;Apply the customer resource definitions (CRDs) and role bindings required to manage the CRDs.&lt;/span&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p style="padding-left: 30px;"&gt;&lt;span style="font-weight: 400;"&gt;&lt;code&gt;$ oc apply -f install/cluster-operator/&lt;/code&gt;&lt;/span&gt;&lt;/p&gt; &lt;ol start="4"&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;The last step will create the Kafka CRD and start the deployment of the Cluster Operator. This operator will keep track of your kafka resources and provision or update the changes to those resources. Open a new browser tab and navigate to your web console URL:&lt;/span&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p style="padding-left: 30px;"&gt;&lt;span style="font-weight: 400;"&gt;&lt;code&gt;https://&amp;#60;your-ip&amp;#62;:8443/console/project/myproject/overview&lt;/code&gt;&lt;/span&gt;&lt;/p&gt; &lt;p style="padding-left: 30px;"&gt;&lt;span style="font-weight: 400;"&gt;Check the assigned IP issuing the &lt;code&gt;minishift ip&lt;/code&gt; command or just run  &lt;code&gt;minishift console&lt;/code&gt; and navigate to &lt;code&gt;My Project&lt;/code&gt;.&lt;/span&gt;&lt;/p&gt; &lt;ol start="5"&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;Login in to the OpenShift web console to check the deployment. Use &lt;code&gt;developer&lt;/code&gt;/&lt;code&gt;developer&lt;/code&gt; as the user and password. If you haven’t done before, accept the self signed certificates in your browser.&lt;/span&gt;&lt;/span&gt;&amp;#160; &lt;p&gt;&lt;img class=" size-large wp-image-531587 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/10/bp-login-ocp-1024x760.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/bp-login-ocp-1024x760.png" alt="" width="640" height="475" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/bp-login-ocp-1024x760.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/bp-login-ocp-300x223.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/bp-login-ocp-768x570.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/li&gt; &lt;li&gt;&lt;span style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;You will see in the project workspace the new deployed Cluster Operator running.&lt;/span&gt;&lt;/span&gt;&lt;img class=" size-large wp-image-531597 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/10/bp-cluster-operator-1024x589.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/bp-cluster-operator-1024x589.png" alt="" width="640" height="368" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/bp-cluster-operator-1024x589.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/bp-cluster-operator-300x173.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/bp-cluster-operator-768x442.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/li&gt; &lt;li style="list-style-type: none;"&gt;&lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;&lt;span style="font-weight: 400;"&gt;Setup your first Apache Kafka Cluster&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;The Cluster Operator now will listen for new Kafka resources. Let’s create a simple Kafka cluster with external access configured, so we are able to connect from outside the OpenShift cluster. &lt;/span&gt;&lt;/p&gt; &lt;ol&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;Create the new &lt;code&gt;my-cluster&lt;/code&gt; kafka Cluster with 3 zookeeper and 3 kafka nodes using &lt;code&gt;ephemeral&lt;/code&gt; storage:&lt;/span&gt; &lt;pre style="padding-left: 30px;"&gt;&lt;span style="font-weight: 400;"&gt;$ cat &amp;#60;&amp;#60; EOF | oc create -f -&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;apiVersion: kafka.strimzi.io/v1alpha1&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;kind: Kafka&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;metadata: &lt;/span&gt; &lt;span style="font-weight: 400;"&gt; name: my-cluster&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;spec:&lt;/span&gt; &lt;span style="font-weight: 400;"&gt; kafka:&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;   replicas: 3&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;   listeners:&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;     external:&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;       type: route&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;   storage:&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;     type: ephemeral&lt;/span&gt; &lt;span style="font-weight: 400;"&gt; zookeeper:&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;   replicas: 3&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;   storage:&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;     type: ephemeral&lt;/span&gt; &lt;span style="font-weight: 400;"&gt; entityOperator:&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;   topicOperator: {}&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;EOF&lt;/span&gt;&lt;/pre&gt; &lt;ol&gt; &lt;li style="list-style-type: none;"&gt; &lt;ol&gt; &lt;li style="list-style-type: none;"&gt;&lt;/li&gt; &lt;/ol&gt; &lt;/li&gt; &lt;/ol&gt; &lt;/li&gt; &lt;li&gt;&lt;span style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;Wait a couple minutes, after that you will see the deployment of the Zookeeper and Kafka resources as well as the topic and user operator.&lt;/span&gt;&lt;/span&gt;&lt;img class=" size-large wp-image-531627 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/10/bp-kafka-cluster-1024x739.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/bp-kafka-cluster-1024x739.png" alt="" width="640" height="462" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/bp-kafka-cluster-1024x739.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/bp-kafka-cluster-300x217.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/bp-kafka-cluster-768x554.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt; &lt;p&gt;&amp;#160;&lt;/li&gt; &lt;li&gt;&lt;span style="font-weight: 400;"&gt;Now that our cluster is running, we can create a topic to publish and subscribe from our external client. Create the following &lt;code&gt;my-topic&lt;/code&gt; Topic custom resource definition with 3 replicas and 3 partitions in &lt;code&gt;my-cluster&lt;/code&gt; Kafka cluster:&lt;/span&gt;&lt;/li&gt; &lt;/ol&gt; &lt;pre style="padding-left: 60px;"&gt;&lt;span style="font-weight: 400;"&gt;$ cat &amp;#60;&amp;#60; EOF | oc create -f -&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;apiVersion: kafka.strimzi.io/v1alpha1&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;kind: KafkaTopic&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;metadata:&lt;/span&gt; &lt;span style="font-weight: 400;"&gt; name: my-topic&lt;/span&gt; &lt;span style="font-weight: 400;"&gt; labels:&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;   strimzi.io/cluster: "my-cluster"&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;spec:&lt;/span&gt; &lt;span style="font-weight: 400;"&gt; partitions: 3&lt;/span&gt; &lt;span style="font-weight: 400;"&gt; replicas: 3&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;EOF&lt;/span&gt;&lt;/pre&gt; &lt;p style="padding-left: 30px;"&gt;&lt;span style="font-weight: 400;"&gt;You are now ready to start sending and receiving messages.&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;&lt;span style="font-weight: 400;"&gt;Test using an external application&lt;/span&gt;&lt;/h2&gt; &lt;ol&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;Clone this &lt;/span&gt;&lt;a href="https://github.com/hguerrero/amq-examples.git"&gt;&lt;span style="font-weight: 400;"&gt;git repo&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; to test the access from to your new Kafka cluster:&lt;/span&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p style="padding-left: 30px;"&gt;&lt;span style="font-weight: 400;"&gt;&lt;code&gt;$ git clone https://github.com/hguerrero/amq-examples.git&lt;/code&gt;&lt;/span&gt;&lt;/p&gt; &lt;ol start="2"&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;Switch to the &lt;code&gt;camel-kafka-demo&lt;/code&gt; folder&lt;/span&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p style="padding-left: 30px;"&gt;&lt;span style="font-weight: 400;"&gt;&lt;code&gt;$ cd amq-examples/camel-kafka-demo/&lt;/code&gt;&lt;/span&gt;&lt;/p&gt; &lt;ol start="3"&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;As we are using &lt;strong&gt;Routes&lt;/strong&gt; for external access to the cluster, we need the CA certs to enable TLS in the client. Extract the public certificate of the broker certification authority&lt;/span&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p style="padding-left: 30px;"&gt;&lt;span style="font-weight: 400;"&gt;&lt;code&gt;$ oc extract secret/my-cluster-cluster-ca-cert --keys=ca.crt --to=- &amp;#62; src/main/resources/ca.crt&lt;/code&gt;&lt;/span&gt;&lt;/p&gt; &lt;ol start="4"&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;Import the trusted cert to a keystore&lt;/span&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p style="padding-left: 30px;"&gt;&lt;span style="font-weight: 400;"&gt;&lt;code&gt;$ keytool -import -trustcacerts -alias root -file src/main/resources/ca.crt -keystore src/main/resources/keystore.jks -storepass password -noprompt&lt;/code&gt;&lt;/span&gt;&lt;/p&gt; &lt;ol start="5"&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;Now you can run the Fuse application using the maven command:&lt;/span&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p style="padding-left: 30px;"&gt;&lt;span style="font-weight: 400;"&gt;&lt;code&gt;$ mvn -Drun.jvmArguments="-Dboostrap.server=`oc get routes my-cluster-kafka-bootstrap -o=jsonpath='{.status.ingress[0].host}{"\n"}'`:443" clean package spring-boot:run&lt;/code&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;After finishing the clean and package phases you will see the Spring Boot application start creating a producer and consumer sending and receiving messages from the “my-topic” Kafka topic.&lt;/span&gt;&lt;/p&gt; &lt;pre style="padding-left: 30px;"&gt;&lt;span style="font-weight: 400;"&gt;14:36:18.170 [main] INFO  com.redhat.kafkademo.Application - Started Application in 12.051 seconds (JVM running for 12.917)&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;14:36:18.490 [Camel (MyCamel) thread #1 - KafkaConsumer[my-topic]] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=6de87ffa-c7cf-441b-b1f8-e55daabc8d12] Discovered coordinator my-cluster-kafka-1-myproject.192.168.99.100.nip.io:443 (id: 2147483646 rack: null)&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;14:36:18.498 [Camel (MyCamel) thread #1 - KafkaConsumer[my-topic]] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=6de87ffa-c7cf-441b-b1f8-e55daabc8d12] Revoking previously assigned partitions []&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;14:36:18.498 [Camel (MyCamel) thread #1 - KafkaConsumer[my-topic]] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=6de87ffa-c7cf-441b-b1f8-e55daabc8d12] (Re-)joining group&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;14:36:19.070 [Camel (MyCamel) thread #3 - KafkaProducer[my-topic]] INFO  producer-route - producer &amp;#62;&amp;#62;&amp;#62; Hello World from camel-context.xml with ID ID-hguerrer-osx-1540578972584-0-2&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;14:36:19.987 [Camel (MyCamel) thread #4 - KafkaProducer[my-topic]] INFO  producer-route - producer &amp;#62;&amp;#62;&amp;#62; Hello World from camel-context.xml with ID ID-hguerrer-osx-1540578972584-0-4&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;14:36:20.982 [Camel (MyCamel) thread #5 - KafkaProducer[my-topic]] INFO  producer-route - producer &amp;#62;&amp;#62;&amp;#62; Hello World from camel-context.xml with ID ID-hguerrer-osx-1540578972584-0-6&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;14:36:21.620 [Camel (MyCamel) thread #1 - KafkaConsumer[my-topic]] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=6de87ffa-c7cf-441b-b1f8-e55daabc8d12] Successfully joined group with generation 1&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;14:36:21.621 [Camel (MyCamel) thread #1 - KafkaConsumer[my-topic]] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=6de87ffa-c7cf-441b-b1f8-e55daabc8d12] Setting newly assigned partitions [my-topic-0, my-topic-1, my-topic-2]&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;14:36:21.959 [Camel (MyCamel) thread #6 - KafkaProducer[my-topic]] INFO  producer-route - producer &amp;#62;&amp;#62;&amp;#62; Hello World from camel-context.xml with ID ID-hguerrer-osx-1540578972584-0-8&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;14:36:21.973 [Camel (MyCamel) thread #1 - KafkaConsumer[my-topic]] INFO  consumer-route - consumer &amp;#62;&amp;#62;&amp;#62; Hello World from camel-context.xml with ID ID-hguerrer-osx-1540578972584-0-8&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;14:36:22.970 [Camel (MyCamel) thread #7 - KafkaProducer[my-topic]] INFO  producer-route - producer &amp;#62;&amp;#62;&amp;#62; Hello World from camel-context.xml with ID ID-hguerrer-osx-1540578972584-0-11&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;14:36:22.975 [Camel (MyCamel) thread #1 - KafkaConsumer[my-topic]] INFO  consumer-route - consumer &amp;#62;&amp;#62;&amp;#62; Hello World from camel-context.xml with ID ID-hguerrer-osx-1540578972584-0-11&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;14:36:23.968 [Camel (MyCamel) thread #8 - KafkaProducer[my-topic]] INFO  producer-route - producer &amp;#62;&amp;#62;&amp;#62; Hello World from camel-context.xml with ID ID-hguerrer-osx-1540578972584-0-14&lt;/span&gt; &lt;/pre&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;You’re done! Press &lt;code&gt;Ctrl + C&lt;/code&gt; to stop the running program.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt; You&amp;#8217;ve seen how easy it is to create an Apache Kafka cluster in OpenShift and be ready to have your applications send and consume messages using it. You can find more information in the official &lt;/span&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_amq_streams/1.0/html-single/using_amq_streams_on_openshift_container_platform/"&gt;&lt;span style="font-weight: 400;"&gt;getting started guide&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; if you want to check more advanced configurations.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Soon, I will publish an another how to configuring configuring Kafka Connect and Kafka Streams with OpenShift and AMQ Streams.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F29%2Fhow-to-run-kafka-on-openshift-the-enterprise-kubernetes-with-amq-streams%2F&amp;#38;linkname=How%20to%20run%20Kafka%20on%20Openshift%2C%20the%20enterprise%20Kubernetes%2C%20with%20AMQ%20Streams" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F29%2Fhow-to-run-kafka-on-openshift-the-enterprise-kubernetes-with-amq-streams%2F&amp;#38;linkname=How%20to%20run%20Kafka%20on%20Openshift%2C%20the%20enterprise%20Kubernetes%2C%20with%20AMQ%20Streams" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F29%2Fhow-to-run-kafka-on-openshift-the-enterprise-kubernetes-with-amq-streams%2F&amp;#38;linkname=How%20to%20run%20Kafka%20on%20Openshift%2C%20the%20enterprise%20Kubernetes%2C%20with%20AMQ%20Streams" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F29%2Fhow-to-run-kafka-on-openshift-the-enterprise-kubernetes-with-amq-streams%2F&amp;#38;linkname=How%20to%20run%20Kafka%20on%20Openshift%2C%20the%20enterprise%20Kubernetes%2C%20with%20AMQ%20Streams" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F29%2Fhow-to-run-kafka-on-openshift-the-enterprise-kubernetes-with-amq-streams%2F&amp;#38;linkname=How%20to%20run%20Kafka%20on%20Openshift%2C%20the%20enterprise%20Kubernetes%2C%20with%20AMQ%20Streams" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F29%2Fhow-to-run-kafka-on-openshift-the-enterprise-kubernetes-with-amq-streams%2F&amp;#38;linkname=How%20to%20run%20Kafka%20on%20Openshift%2C%20the%20enterprise%20Kubernetes%2C%20with%20AMQ%20Streams" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F29%2Fhow-to-run-kafka-on-openshift-the-enterprise-kubernetes-with-amq-streams%2F&amp;#38;linkname=How%20to%20run%20Kafka%20on%20Openshift%2C%20the%20enterprise%20Kubernetes%2C%20with%20AMQ%20Streams" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F29%2Fhow-to-run-kafka-on-openshift-the-enterprise-kubernetes-with-amq-streams%2F&amp;#38;linkname=How%20to%20run%20Kafka%20on%20Openshift%2C%20the%20enterprise%20Kubernetes%2C%20with%20AMQ%20Streams" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F29%2Fhow-to-run-kafka-on-openshift-the-enterprise-kubernetes-with-amq-streams%2F&amp;#38;title=How%20to%20run%20Kafka%20on%20Openshift%2C%20the%20enterprise%20Kubernetes%2C%20with%20AMQ%20Streams" data-a2a-url="https://developers.redhat.com/blog/2018/10/29/how-to-run-kafka-on-openshift-the-enterprise-kubernetes-with-amq-streams/" data-a2a-title="How to run Kafka on Openshift, the enterprise Kubernetes, with AMQ Streams"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/10/29/how-to-run-kafka-on-openshift-the-enterprise-kubernetes-with-amq-streams/"&gt;How to run Kafka on Openshift, the enterprise Kubernetes, with AMQ Streams&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/SLzpc6LTvW0" height="1" width="1" alt=""/&gt;</content><summary>On October 25th Red Hat announced the general availability of their AMQ Streams Kubernetes Operator for Apache Kafka. Red Hat AMQ Streams focuses on running Apache Kafka on Openshift providing a massively-scalable, distributed, and high performance data streaming platform. AMQ Streams, based on the Apache Kafka and Strimzi projects, offers a distributed backbone that allows microservices and other...</summary><dc:creator>Hugo Guerrero</dc:creator><dc:date>2018-10-29T11:00:53Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/10/29/how-to-run-kafka-on-openshift-the-enterprise-kubernetes-with-amq-streams/</feedburner:origLink></entry><entry><title>Hibernate Community Newsletter 21/2018</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/s4-vYmdg0Zg/" /><category term="Discussions" scheme="searchisko:content:tags" /><category term="feed_group_name_hibernate" scheme="searchisko:content:tags" /><category term="feed_name_inrelationto" scheme="searchisko:content:tags" /><category term="Hibernate ORM" scheme="searchisko:content:tags" /><category term="newsletter" scheme="searchisko:content:tags" /><author><name>Vlad Mihalcea</name></author><id>searchisko:content:id:jbossorg_blog-hibernate_community_newsletter_21_2018</id><updated>2018-10-30T11:09:17Z</updated><published>2018-10-29T00:00:00Z</published><content type="html">&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Welcome to the Hibernate community newsletter in which we share blog posts, forum, and StackOverflow questions that are especially relevant to our users.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="market-share"&gt;&lt;a class="anchor" href="#market-share"&gt;&lt;/a&gt;Market share&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;According to the &lt;a href="https://snyk.io/blog/jvm-ecosystem-report-2018-platform-application"&gt;2018 JVM ecosystem report published by Snyk&lt;/a&gt;, Hibernate has a 54% market share, making it the most popular Java data access technology.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Although it’s been available since 2001, Hibernate has been evolving constantly, and the Hibernate ORM version 6 is going to bring many new features and improvements, so stay tuned!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="articles"&gt;&lt;a class="anchor" href="#articles"&gt;&lt;/a&gt;Articles&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;JPA 2.2 supports the following &lt;code&gt;java.time&lt;/code&gt; types introduced by Java 8:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;java.time.LocalDate&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;java.time.LocalTime&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;java.time.LocalDateTime&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;java.time.OffsetTime&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;java.time.OffsetDateTime&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Apart from supporting all those types, Hibernate provides the following extra types:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;java.time.Duration&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;java.time.Instant&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;java.time.ZonedDateTime&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;However, neither JPA nor Hibernate support the &lt;code&gt;java.time.Year&lt;/code&gt; and &lt;code&gt;java.time.YearMonth&lt;/code&gt; out-of-the-box. The following two articles show you how to support these types when using JPA and Hibernate:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://vladmihalcea.com/java-time-year-month-jpa-hibernate/"&gt;How to map &lt;code&gt;java.time.Year&lt;/code&gt; and &lt;code&gt;java.time.Month&lt;/code&gt; with JPA and Hibernate&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://vladmihalcea.com/java-yearmonth-jpa-hibernate/"&gt;How to map the Java &lt;code&gt;YearMonth&lt;/code&gt; type with JPA and Hibernate&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Eugen Paraschiv wrote two articles about Hibernate:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.baeldung.com/stored-procedures-with-hibernate-tutorial"&gt;How to use stored procedures with Hibernate&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.baeldung.com/hibernate-custom-types"&gt;How to implement custom types with Hibernate&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="questions-and-answers"&gt;&lt;a class="anchor" href="#questions-and-answers"&gt;&lt;/a&gt;Questions and answers&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/hibernate-lazy-mode-doesnt-work-with-spring-boot/1535"&gt;Hibernate Lazy Mode doesn’t work with Spring Boot&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/43059147/hibernate-serialize-java-time-year-and-others/52886156#52886156"&gt;How to map &lt;code&gt;java.time.Year&lt;/code&gt; and others &lt;code&gt;java.time&lt;/code&gt; types using Hibernate&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/52850442/getting-rid-if-n1-with-jpa-criteria-api-in-hibernate/52945771#52945771"&gt;How to get rid of N+1 with JPA Criteria API in Hibernate&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/hiberante-returns-stale-data-from-the-cache-instead-of-the-latest-record-from-the-db/1592"&gt;Hibernate returns stale data from the cache instead of the latest record from the DB&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/42256527/how-to-avoid-java-util-concurrentmodificationexception-in-entity-merging-in-jpa/42266413#42266413"&gt;How to avoid java.util.ConcurrentModificationException in entity merging in JPA and Hibernate&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/hibernate-postgresql-jsonb-issue-no-dialect-mapping-for-jdbc-type-1111/1612"&gt;Hibernate PostgreSQL JSONB issue: No Dialect mapping for JDBC type: 1111&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/52988292/possibility-of-race-condition-during-time-slot-between-hibernate-optimistic-lock/53034456#53034456"&gt;Possibility of race condition during time slot between Hibernate optimistic locking version check and transaction commit&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/7349464/bulk-insert-or-update-with-hibernate/51324134#51324134"&gt;Bulk insert or update with Hibernate?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/error-while-reading-the-hbm-xml-file/1577"&gt;Error while reading the hbm.xml file&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/jpa-entity-with-abstract-field-needs-discriminator/1554"&gt;JPA entity with abstract field needs discriminator&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/should-i-use-an-application-generated-entity-identifier-or-use-the-database-native-generator-with-hibernate/1493/12"&gt;Should I use an application-generated entity identifier or use the database native generator with Hibernate?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/does-hibernate-provide-a-way-to-invalidate-l2-cache/1405/5"&gt;Does Hibernate provide a way to invalidate L2 cache?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/hibernate-query-cache/1558"&gt;Hibernate query cache and consistency issues&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/criteria-stopped-working-after-upgrading-hibernate-orm-to-5-3-7/1556"&gt;Criteria stopped working after upgrading Hibernate ORM to 5.3.7&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/53019285/how-to-set-parentid-in-child-entity-of-one-to-many-mapping-using-spring-boot-dat/53019467#53019467"&gt;How to set the &lt;code&gt;parentId&lt;/code&gt; property in a child Entity of one-to-many mapping using Spring Boot Data JPA&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/s4-vYmdg0Zg" height="1" width="1" alt=""/&gt;</content><summary>Welcome to the Hibernate community newsletter in which we share blog posts, forum, and StackOverflow questions that are especially relevant to our users. Market share According to the 2018 JVM ecosystem report published by Snyk, Hibernate has a 54% market share, making it the most popular Java data access technology. Although it’s been available since 2001, Hibernate has been evolving constantly, ...</summary><dc:creator>Vlad Mihalcea</dc:creator><dc:date>2018-10-29T00:00:00Z</dc:date><feedburner:origLink>http://in.relation.to/2018/10/29/hibernate-community-newsletter-2018-21/</feedburner:origLink></entry><entry><title>How to install Ansible Tower on Red Hat OpenShift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ZOBHEt1c2i4/" /><category term="ansible" scheme="searchisko:content:tags" /><category term="Ansible Tower" scheme="searchisko:content:tags" /><category term="Automation" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="devops" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Container Platform" scheme="searchisko:content:tags" /><author><name>Michele Naldini</name></author><id>searchisko:content:id:jbossorg_blog-how_to_install_ansible_tower_on_red_hat_openshift</id><updated>2018-10-26T22:25:56Z</updated><published>2018-10-26T22:25:56Z</published><content type="html">&lt;p&gt;In this article, I will show how to install and manage &lt;a href="https://www.redhat.com/en/technologies/management/ansible"&gt;Red Hat Ansible Tower&lt;/a&gt; on &lt;a href="https://developers.redhat.com/products/openshift/"&gt;Red Hat OpenShift Container Platform&lt;/a&gt;. Ansible Tower helps you scale IT automation, manage complex deployments, and improve productivity. You can centralize and control your IT infrastructure with a visual dashboard, and it provides role-based access control, job scheduling, integrated notifications, graphical inventory management, and more.&lt;/p&gt; &lt;p&gt;As you may know, Ansible Tower 3.3, the latest release of this automation platform, was released a few weeks ago and added new features. From the &lt;a href="https://docs.ansible.com/ansible-tower/latest/html/release-notes/relnotes.html#ansible-tower-version-3-3-0"&gt;release notes&lt;/a&gt; you&amp;#8217;ll see that Ansible Tower 3.3 added support for a container-based installation on top of OpenShift or &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;In this blog, we&amp;#8217;ll see how easy it is to set up Ansible Tower 3.3 on OpenShift and have it running as a &lt;a href="https://developers.redhat.com/blog/category/containers/"&gt;container&lt;/a&gt; in just a few minutes.&lt;/p&gt; &lt;p&gt;&lt;span id="more-527517"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Overview of the process&lt;/h2&gt; &lt;p&gt;We&amp;#8217;ll follow these steps:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Log in on an existing OpenShift installation.&lt;/li&gt; &lt;li&gt;Create a dedicated project where Ansible Tower will be installed.&lt;/li&gt; &lt;li&gt;Create a persistent volume claim (PVC) and, if it&amp;#8217;s not already present, create a physical volume (PV).&lt;/li&gt; &lt;li&gt;Start the installation process.&lt;/li&gt; &lt;li&gt;Finally, use Ansible Tower as a service and perform a scale-out.&lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;Resources and requirements&lt;/h2&gt; &lt;p&gt;Refer to the following resources:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://docs.ansible.com/ansible-tower/3.3.0/html/administration/openshift_configuration.html"&gt;OpenShift Deployment and Configuration&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://releases.ansible.com/ansible-tower/setup_openshift/"&gt;Download Ansible tower OpenShift setup script&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The requirements mentioned in &lt;a href="https://docs.ansible.com/ansible-tower/3.3.0/html/administration/openshift_configuration.html"&gt;OpenShift Deployment and Configuration&lt;/a&gt; for Ansible Tower on OpenShift are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Red Hat OpenShift 3.6+&lt;/li&gt; &lt;li&gt;Per-pod default resource requirements: &lt;ul&gt; &lt;li&gt;6GB RAM&lt;/li&gt; &lt;li&gt;3 CPU cores&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;OpenShift command-line tool (&lt;code&gt;oc&lt;/code&gt;) on the machine running the installer&lt;/li&gt; &lt;li&gt;A set-up and running OpenShift cluster&lt;/li&gt; &lt;li&gt;Admin privileges for the account running the OpenShift installer&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Procedure&lt;/h2&gt; &lt;p&gt;So let&amp;#8217;s start to create the Ansible Tower prerequisites on OpenShift. First, let&amp;#8217;s log in:&lt;/p&gt; &lt;pre&gt;$ oc login myamazingopenshiftcluster -u myuser -p mypassword Username: myuser Password: Login successful. You have access to the following projects and can switch between them with 'oc project &amp;#60;projectname&amp;#62;': *default kube-public kube-service-catalog kube-system management-infra ocp-workshop openshift openshift-ansible-service-broker openshift-infra openshift-logging openshift-node openshift-sdn openshift-template-service-broker openshift-web-console Using project "default". The server uses a certificate signed by an unknown authority. You can bypass the certificate check, but any data you send to the server could be intercepted by others. Use insecure connections? (y/n): y Login successful.&lt;/pre&gt; &lt;p&gt;Let&amp;#8217;s create a new project called &lt;code&gt;tower&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;$ oc new-project tower Now using project "tower" on server "https://myamazingopenshiftcluster :443". You can add applications to this project with the 'new-app' command. For example, try: $ oc new-app centos/ruby-22-centos7~https://github.com/openshift/ruby-ex.git to build a new example application in Ruby. &lt;/pre&gt; &lt;p&gt;As additional prerequisites, Ansible Tower requires a PVC to be used by a Postgres database to persist its data.&lt;/p&gt; &lt;p&gt;In our case, we are going to create a 10 GB PVC using this YAML file:&lt;/p&gt; &lt;pre&gt;$ cat postgres-nfs-pvc apiVersion: v1 kind: PersistentVolumeClaim metadata: name: postgresql spec: accessModes: - ReadWriteOnce resources: requests: storage: 10Gi&lt;/pre&gt; &lt;p&gt;Now we can ask OpenShift to create the PVC for us:&lt;/p&gt; &lt;pre&gt;$ oc create -f postgres-nfs-pvc persistentvolumeclaim "postgresql" created&lt;/pre&gt; &lt;p&gt;Our PVC will be bound to a PV that matches the access method and size.&lt;/p&gt; &lt;p&gt;If you don&amp;#8217;t have a PV that will be claimed by our PVC, you can follow the official &lt;a href="https://access.redhat.com/documentation/en-us/openshift_container_platform/3.11/html-single/developer_guide/#dev-guide-volumes"&gt;OpenShift documentation&lt;/a&gt; to create it.&lt;/p&gt; &lt;pre&gt;$ oc get pvc NAME         STATUS VOLUME    CAPACITY ACCESS MODES   STORAGECLASS AGE postgresql   Bound vol118    10Gi RWO,RWX        2s&lt;/pre&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;Last, you have to &lt;a href="https://releases.ansible.com/ansible-tower/setup_openshift/"&gt;download the installation setup tar file&lt;/a&gt;,  untar it, and then execute the following:&lt;/p&gt; &lt;pre&gt;$ ./setup_openshift.sh -e openshift_host=https://myamazingopenshiftcluster:443 -e openshift_project=tower -e openshift_user=myuser -e openshift_password=mypassword -e admin_password=toweradminpwd-e secret_key=mysecret -e pg_username=postgresuser -e pg_password=postgrespwd -e rabbitmq_password=rabbitpwd -e rabbitmq_erlang_cookie=rabbiterlangpwd&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;setup_openshift.sh&lt;/code&gt; script will execute some Ansible playbooks and those will manage for you the entire installation by creating your pods, services, and routes.&lt;/p&gt; &lt;p&gt;That&amp;#8217;s all! In a few minutes, Ansible Tower will be up and running.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/img_5bc098d45dc2b.png"&gt;&lt;img class=" aligncenter wp-image-527587 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/10/img_5bc098d45dc2b-1024x535.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/img_5bc098d45dc2b.png" alt="Ansible Tower set up in Red Hat OpenShift Container Platform" width="2554" height="1334" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/img_5bc098d45dc2b.png 2554w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/img_5bc098d45dc2b-300x157.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/img_5bc098d45dc2b-768x401.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/img_5bc098d45dc2b-1024x535.png 1024w" sizes="(max-width: 2554px) 100vw, 2554px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s now investigate how Ansible Tower was installed. As you may notice from the UI, there is one pod composed of four containers managed through a &lt;code&gt;StatefulSet&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Run the following command from the CLI:&lt;/p&gt; &lt;pre&gt;$ oc describe sts ansible-tower Name: ansible-tower Namespace: tower CreationTimestamp: Tue, 09 Oct 2018 17:14:51 +0200 Selector: app=ansible-tower,name=ansible-tower-web-deploy,service=django Labels: app=ansible-tower name=ansible-tower-web-deploy service=django Annotations: kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"apps/v1beta1","kind":"StatefulSet","metadata":{"annotations":{},"name":"ansible-tower","namespace":"tower"},"spec":{"replicas":1,"templa... Replicas: 1 desired | 1 total Pods Status: 1 Running / 0 Waiting / 0 Succeeded / 0 Failed Pod Template: Labels: app=ansible-tower name=ansible-tower-web-deploy service=django Service Account: awx Containers: &lt;em&gt;output truncated&lt;/em&gt;&lt;/pre&gt; &lt;p&gt;As you may notice, the &lt;code&gt;Replicas&lt;/code&gt; value is 1, so one pod (that is, one Ansible Tower instance) will be running.&lt;/p&gt; &lt;p&gt;The good thing is that if you can scale up your &lt;code&gt;StatefulSet&lt;/code&gt; replica count, Ansible Tower will be scaled accordingly!&lt;/p&gt; &lt;p&gt;You can manage this change by using the UI and editing the YAML file or by using &lt;code&gt;oc&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Take a look at the current status:&lt;/p&gt; &lt;pre&gt;$ oc get sts NAME DESIRED CURRENT AGE ansible-tower 1 1 3d&lt;/pre&gt; &lt;p&gt;Here&amp;#8217;s how to scale up:&lt;/p&gt; &lt;pre&gt;$ oc scale --replicas=2 sts ansible-tower statefulset "ansible-tower" scaled&lt;/pre&gt; &lt;p&gt;Now check the running configuration again:&lt;/p&gt; &lt;pre&gt;$ oc get sts NAME DESIRED CURRENT AGE ansible-tower 2 2 3d&lt;/pre&gt; &lt;p&gt;Here&amp;#8217;s what the web console shows now:&lt;/p&gt; &lt;p id="ArWqLjK"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/img_5bc0d47b8f34d.png"&gt;&lt;img class=" aligncenter wp-image-527737 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/10/img_5bc0d47b8f34d-1024x536.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/img_5bc0d47b8f34d.png" alt="The result after scaling up" width="2473" height="1294" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/img_5bc0d47b8f34d.png 2473w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/img_5bc0d47b8f34d-300x157.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/img_5bc0d47b8f34d-768x402.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/img_5bc0d47b8f34d-1024x536.png 1024w" sizes="(max-width: 2473px) 100vw, 2473px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;That&amp;#8217;s all! If you want to see a short demo of the process, check out this video:&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;iframe class='youtube-player' type='text/html' width='640' height='360' src='https://www.youtube.com/embed/o-OrUq6FAe0?version=3&amp;#038;rel=1&amp;#038;fs=1&amp;#038;autohide=2&amp;#038;showsearch=0&amp;#038;showinfo=1&amp;#038;iv_load_policy=1&amp;#038;wmode=transparent' allowfullscreen='true' style='border:0;'&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F26%2Finstalling-and-managing-ansible-tower-on-red-hat-openshift-container-platform%2F&amp;#38;linkname=How%20to%20install%20Ansible%20Tower%20on%20Red%20Hat%20OpenShift" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F26%2Finstalling-and-managing-ansible-tower-on-red-hat-openshift-container-platform%2F&amp;#38;linkname=How%20to%20install%20Ansible%20Tower%20on%20Red%20Hat%20OpenShift" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F26%2Finstalling-and-managing-ansible-tower-on-red-hat-openshift-container-platform%2F&amp;#38;linkname=How%20to%20install%20Ansible%20Tower%20on%20Red%20Hat%20OpenShift" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F26%2Finstalling-and-managing-ansible-tower-on-red-hat-openshift-container-platform%2F&amp;#38;linkname=How%20to%20install%20Ansible%20Tower%20on%20Red%20Hat%20OpenShift" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F26%2Finstalling-and-managing-ansible-tower-on-red-hat-openshift-container-platform%2F&amp;#38;linkname=How%20to%20install%20Ansible%20Tower%20on%20Red%20Hat%20OpenShift" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F26%2Finstalling-and-managing-ansible-tower-on-red-hat-openshift-container-platform%2F&amp;#38;linkname=How%20to%20install%20Ansible%20Tower%20on%20Red%20Hat%20OpenShift" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F26%2Finstalling-and-managing-ansible-tower-on-red-hat-openshift-container-platform%2F&amp;#38;linkname=How%20to%20install%20Ansible%20Tower%20on%20Red%20Hat%20OpenShift" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F26%2Finstalling-and-managing-ansible-tower-on-red-hat-openshift-container-platform%2F&amp;#38;linkname=How%20to%20install%20Ansible%20Tower%20on%20Red%20Hat%20OpenShift" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F26%2Finstalling-and-managing-ansible-tower-on-red-hat-openshift-container-platform%2F&amp;#38;title=How%20to%20install%20Ansible%20Tower%20on%20Red%20Hat%20OpenShift" data-a2a-url="https://developers.redhat.com/blog/2018/10/26/installing-and-managing-ansible-tower-on-red-hat-openshift-container-platform/" data-a2a-title="How to install Ansible Tower on Red Hat OpenShift"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/10/26/installing-and-managing-ansible-tower-on-red-hat-openshift-container-platform/"&gt;How to install Ansible Tower on Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ZOBHEt1c2i4" height="1" width="1" alt=""/&gt;</content><summary>In this article, I will show how to install and manage Red Hat Ansible Tower on Red Hat OpenShift Container Platform. Ansible Tower helps you scale IT automation, manage complex deployments, and improve productivity. You can centralize and control your IT infrastructure with a visual dashboard, and it provides role-based access control, job scheduling, integrated notifications, graphical inventory...</summary><dc:creator>Michele Naldini</dc:creator><dc:date>2018-10-26T22:25:56Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/10/26/installing-and-managing-ansible-tower-on-red-hat-openshift-container-platform/</feedburner:origLink></entry><entry><title>Welcome Apache Kafka to the Kubernetes Era!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/lNrph9_MQKY/" /><category term="Announcement" scheme="searchisko:content:tags" /><category term="Apache Kafka" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="jboss a-mq" scheme="searchisko:content:tags" /><category term="Kafka streams" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="Kubernetes Operator" scheme="searchisko:content:tags" /><category term="microservices" scheme="searchisko:content:tags" /><category term="Modern App Dev" scheme="searchisko:content:tags" /><category term="Red Hat AMQ" scheme="searchisko:content:tags" /><category term="Red Hat AMQ Streams" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift" scheme="searchisko:content:tags" /><category term="Stream Processing" scheme="searchisko:content:tags" /><author><name>Hugo Guerrero</name></author><id>searchisko:content:id:jbossorg_blog-welcome_apache_kafka_to_the_kubernetes_era</id><updated>2018-10-25T15:00:07Z</updated><published>2018-10-25T15:00:07Z</published><content type="html">&lt;p&gt;&lt;span style="font-weight: 400;"&gt;We have pretty exciting news this week as Red Hat is announcing the General Availability of their Apache Kafka &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt; operator. Red Hat AMQ Streams delivers the mechanisms for managing Apache Kafka on top of OpenShift, our enterprise distribution for Kubernetes. &lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Everything started last May 2018 when David Ingham (@dingha)&lt;/span&gt;&lt;a href="https://developers.redhat.com/blog/2018/05/07/announcing-amq-streams-apache-kafka-on-openshift/"&gt; &lt;span style="font-weight: 400;"&gt;unveiled the Developer Preview&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; as new addition to the&lt;/span&gt;&lt;a href="https://developers.redhat.com/products/amq/overview/"&gt; &lt;span style="font-weight: 400;"&gt;Red Hat AMQ&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; offering. Red Hat AMQ Streams focuses on running Apache Kafka on OpenShift. In the &lt;a href="https://developers.redhat.com/topics/microservices/"&gt;microservices&lt;/a&gt; world, where several components need to rely on a high throughput communication mechanism, Apache Kafka has made a name for itself for being a leading real-time, distributed messaging platform for building data pipelines and streaming applications. &lt;/span&gt;&lt;span id="more-531027"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;A leader in the traditional infrastructure deployments, Apache Kafka was missing pieces to be a easily usable container-native citizen in the new&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;Kubernetes&lt;/span&gt;&lt;span style="font-weight: 400;"&gt; era.  As a result, a team grouped in 2017 to create the upstream &lt;/span&gt;&lt;a href="http://strimzi.io/"&gt;&lt;span style="font-weight: 400;"&gt;Strimzi&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; project. This team worked to apply the new &lt;/span&gt;&lt;a href="https://coreos.com/blog/introducing-operators.html"&gt;&lt;span style="font-weight: 400;"&gt;operator pattern&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; to solve the gaps. With the development of new components deployed along the traditional Apache Kafka broker, these new Kubernetes operators are now able to manage cluster wide resources as well as entities as topics and authentication users.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Even more, these Kubernetes operators are pretty simple to use and cover most of the more common configuration management of a cluster. After doing some Kubernetes Custom Resource Definition installations in OpenShift, any user is able to create an Apache Kafka cluster by just creating a new Kafka resource definition. Then, the cluster operator will take that definition and provision the required components to have a fully deployed cluster on top of your OpenShift infrastructure. The same applies for the creation of Topics and Users for that same Kafka cluster.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Finally, the most interesting part, is the simple configuration to provision a cluster that&amp;#8217;s easily available from outside the OpenShift cluster via NodePorts, Load Balancers or Routes, the latter being  the easiest way to start working. Depending on your application requirements, you will be able to choose from using the simple secure over TLS approach or the traditional NodePort settings. As a result, the AMQ Streams operators embedded logic creates dynamic services, routes and certificates to access the Apache Kafka cluster from external clients. &lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Yes, it sounds like magic. That’s how good it is! Give Red Hat AMQ Streams a try by downloading Red Hat Container Development Kit for an OpenShift development environment and following our &lt;/span&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_amq_streams/1.0/html/using_amq_streams/"&gt;&lt;span style="font-weight: 400;"&gt;Getting Started Guide&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt;. Also, be aware of my (soon to be published) HOW-TO guide for Kafka on OpenShift, the enterprise Kubernetes!&lt;/span&gt;&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;Here are some other articles on Apache Kafka and Red Hat AMQ Streams:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/05/07/announcing-amq-streams-apache-kafka-on-openshift/"&gt;Announcing AMQ Streams: Apache Kafka on OpenShift&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/07/16/smart-meter-streams-kafka-openshift/"&gt;Smart-Meter Data Processing Using Apache Kafka on OpenShift&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/10/15/eventflow-event-driven-microservices-on-openshift-part-1/"&gt;EventFlow: Event-driven microservices on OpenShift (Part 1)&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/07/26/detecting-credit-card-fraud-with-red-hat-decision-manager-7/"&gt;Detecting credit card fraud with Red Hat Decision Manager 7&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/05/31/introducing-the-kafka-cdi-library/"&gt;Introducing the Kafka-CDI Library&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F25%2Fwelcome-apache-kafka-to-the-kubernetes-era%2F&amp;#38;linkname=Welcome%20Apache%20Kafka%20to%20the%20Kubernetes%20Era%21" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F25%2Fwelcome-apache-kafka-to-the-kubernetes-era%2F&amp;#38;linkname=Welcome%20Apache%20Kafka%20to%20the%20Kubernetes%20Era%21" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F25%2Fwelcome-apache-kafka-to-the-kubernetes-era%2F&amp;#38;linkname=Welcome%20Apache%20Kafka%20to%20the%20Kubernetes%20Era%21" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F25%2Fwelcome-apache-kafka-to-the-kubernetes-era%2F&amp;#38;linkname=Welcome%20Apache%20Kafka%20to%20the%20Kubernetes%20Era%21" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F25%2Fwelcome-apache-kafka-to-the-kubernetes-era%2F&amp;#38;linkname=Welcome%20Apache%20Kafka%20to%20the%20Kubernetes%20Era%21" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F25%2Fwelcome-apache-kafka-to-the-kubernetes-era%2F&amp;#38;linkname=Welcome%20Apache%20Kafka%20to%20the%20Kubernetes%20Era%21" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F25%2Fwelcome-apache-kafka-to-the-kubernetes-era%2F&amp;#38;linkname=Welcome%20Apache%20Kafka%20to%20the%20Kubernetes%20Era%21" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F25%2Fwelcome-apache-kafka-to-the-kubernetes-era%2F&amp;#38;linkname=Welcome%20Apache%20Kafka%20to%20the%20Kubernetes%20Era%21" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F25%2Fwelcome-apache-kafka-to-the-kubernetes-era%2F&amp;#38;title=Welcome%20Apache%20Kafka%20to%20the%20Kubernetes%20Era%21" data-a2a-url="https://developers.redhat.com/blog/2018/10/25/welcome-apache-kafka-to-the-kubernetes-era/" data-a2a-title="Welcome Apache Kafka to the Kubernetes Era!"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/10/25/welcome-apache-kafka-to-the-kubernetes-era/"&gt;Welcome Apache Kafka to the Kubernetes Era!&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/lNrph9_MQKY" height="1" width="1" alt=""/&gt;</content><summary>We have pretty exciting news this week as Red Hat is announcing the General Availability of their Apache Kafka Kubernetes operator. Red Hat AMQ Streams delivers the mechanisms for managing Apache Kafka on top of OpenShift, our enterprise distribution for Kubernetes. Everything started last May 2018 when David Ingham (@dingha) unveiled the Developer Preview as new addition to the Red Hat AMQ offeri...</summary><dc:creator>Hugo Guerrero</dc:creator><dc:date>2018-10-25T15:00:07Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/10/25/welcome-apache-kafka-to-the-kubernetes-era/</feedburner:origLink></entry></feed>
